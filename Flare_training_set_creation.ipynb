{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initial Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "task1_train = pd.read_json('Flares-dataset/5w1h_subtarea_1_train.json', lines=True)\n",
    "task1_test = pd.read_json('Flares-dataset/5w1h_subtask_1_trial.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame train: (1585, 3)\n",
      "Shape of the DataFrame test: (168, 3)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the DataFrame\n",
    "print(\"Shape of the DataFrame train:\", task1_train.shape)\n",
    "print(\"Shape of the DataFrame test:\", task1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set has a total of 1585 samples and the test set 168."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>732</td>\n",
       "      <td>Dos días, exactamente han pasado dos días desd...</td>\n",
       "      <td>[{'Tag_Start': 52, 'Tag_End': 59, '5W1H_Label'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219</td>\n",
       "      <td>Pero no pasará nada, el PSOE no exigirá la dim...</td>\n",
       "      <td>[{'Tag_Start': 21, 'Tag_End': 28, '5W1H_Label'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id                                               Text  \\\n",
       "0  732  Dos días, exactamente han pasado dos días desd...   \n",
       "1  219  Pero no pasará nada, el PSOE no exigirá la dim...   \n",
       "\n",
       "                                                Tags  \n",
       "0  [{'Tag_Start': 52, 'Tag_End': 59, '5W1H_Label'...  \n",
       "1  [{'Tag_Start': 21, 'Tag_End': 28, '5W1H_Label'...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates found: 168\n",
      "Duplicate Entries:\n",
      "0       72\n",
      "1       64\n",
      "2       49\n",
      "3      130\n",
      "4       61\n",
      "      ... \n",
      "163     23\n",
      "164    129\n",
      "165    102\n",
      "166      0\n",
      "167    104\n",
      "Name: Id, Length: 168, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure both dataframes have an 'Id' column\n",
    "if 'Id' in task1_train.columns and 'Id' in task1_test.columns:\n",
    "    # Identify duplicate IDs\n",
    "    duplicates_mask = task1_test['Id'].isin(task1_train['Id'])\n",
    "    duplicate_ids = task1_test[duplicates_mask]\n",
    "\n",
    "    # Print the number of duplicates\n",
    "    print(f\"Number of duplicates found: {duplicate_ids.shape[0]}\")\n",
    "\n",
    "    # Print the actual duplicate entries\n",
    "    if duplicate_ids.shape[0] > 0:\n",
    "        print(\"Duplicate Entries:\")\n",
    "        print(duplicate_ids['Id'])\n",
    "    else:\n",
    "        print(\"No duplicate entries found.\")\n",
    "else:\n",
    "    print(\"Error: 'id' column not found in one or both DataFrames.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set is a subset of the training set. In order to make a honest evaluation, we will need to split the train set into a train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure pandas does not truncate any text output\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589    El experto ha acompañado el mensaje con una fotografía de uno de los casos observados, en el que se ve una lengua manchada o descolorida. \n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to get the 'Text' for the entry with Id == 1476\n",
    "text_data = task1_train[task1_train['Id'] == 956]['Text']\n",
    "\n",
    "# Print the content\n",
    "print(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can Extract the text based on Tag_Start and Tag_End."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your text\n",
    "text = task1_train['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text: Sánchez, 5W1H Label: WHO\n",
      "Extracted Text: en rueda de prensa en la Moncloa, 5W1H Label: WHERE\n",
      "Extracted Text: a España, 5W1H Label: WHO\n",
      "Extracted Text: entre abril y septiembre, 5W1H Label: WHEN\n",
      "Extracted Text: un total de 87 millones de vacunas, 5W1H Label: WHAT\n",
      "Extracted Text: las mentiras, 5W1H Label: WHAT\n",
      "Extracted Text: de Sánchez, 5W1H Label: WHO\n",
      "Extracted Text: ese refrán que dice, 5W1H Label: WHAT\n"
     ]
    }
   ],
   "source": [
    "# Loop through each tag in the first item of task1_train['Tags']\n",
    "for tag in task1_train['Tags'][0]:\n",
    "    # Extract the text based on Tag_Start and Tag_End\n",
    "    extracted_text = text[tag['Tag_Start']:tag['Tag_End']]\n",
    "    # Print the extracted text and the corresponding 5W1H label\n",
    "    print(f\"Extracted Text: {extracted_text}, 5W1H Label: {tag['5W1H_Label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que “la mentira tiene las patas muy cortas”.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\"input\": text, \"output\": \"Text: Sánchez, 5W1H Label: WHO\\nText: en rueda de prensa en la Moncloa, 5W1H Label: WHERE\\nText: a España, 5W1H Label: WHO\\nText: entre abril y septiembre, 5W1H Label: WHEN\\nText: un total de 87 millones de vacunas, 5W1H Label: WHAT\\nText: las mentiras, 5W1H Label: WHAT\\nText: de Sánchez, 5W1H Label: WHO\\nText: ese refrán que dice, 5W1H Label: WHAT\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of possible output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Sánchez, 5W1H Label: WHO\n",
      "Text: en rueda de prensa en la Moncloa, 5W1H Label: WHERE\n",
      "Text: a España, 5W1H Label: WHO\n",
      "Text: entre abril y septiembre, 5W1H Label: WHEN\n",
      "Text: un total de 87 millones de vacunas, 5W1H Label: WHAT\n",
      "Text: las mentiras, 5W1H Label: WHAT\n",
      "Text: de Sánchez, 5W1H Label: WHO\n",
      "Text: ese refrán que dice, 5W1H Label: WHAT\n"
     ]
    }
   ],
   "source": [
    "print(x['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of model output for Generative model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Sánchez, 5W1H Label: WHO\n",
      "Text: en rueda de prensa en la Moncloa, 5W1H Label: WHERE\n",
      "Text: a España, 5W1H Label: WHO\n",
      "Text: entre abril y septiembre, 5W1H Label: WHEN\n",
      "Text: un total de 87 millones de vacunas, 5W1H Label: WHAT\n",
      "Text: las mentiras, 5W1H Label: WHAT\n",
      "Text: de Sánchez, 5W1H Label: WHO\n",
      "Text: ese refrán que dice, 5W1H Label: WHAT\n"
     ]
    }
   ],
   "source": [
    "formatted_data = []  # List to hold the formatted dictionaries\n",
    "\n",
    "for i in range(len(task1_train['Text'])):\n",
    "    # Constructing the 'input' part\n",
    "    input_text = task1_train['Text'][i]\n",
    "    \n",
    "    # Initializing the 'output' part\n",
    "    output_text = ''\n",
    "    \n",
    "    # Loop through each tag and append the extracted text and 5W1H label to 'output'\n",
    "    for tag in task1_train['Tags'][i]:\n",
    "        extracted_text = input_text[tag['Tag_Start']:tag['Tag_End']]\n",
    "        output_text += f\"Text: {extracted_text}, 5W1H Label: {tag['5W1H_Label']}\\n\"\n",
    "    \n",
    "    # Remove the last newline and space\n",
    "    output_text = output_text.rstrip('\\n ')\n",
    "    \n",
    "    # Append the formatted dictionary to the list\n",
    "    formatted_data.append({'input': input_text, 'output': output_text})\n",
    "\n",
    "# Now `formatted_data` contains all your formatted dictionaries\n",
    "# Here's how you can print the first formatted dictionary to check\n",
    "print(formatted_data[0]['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the current test set is a subset of the training set, we will create a new, independent split from the training data to ensure a fair evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "task1_train = pd.read_json('Flares-dataset/5w1h_subtarea_1_train.json', lines=True)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "train_set, test_set = train_test_split(task1_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the training set as JSON\n",
    "train_set.to_json('Flares-dataset/5w1h_subtarea_1_train_train.json', orient='records', lines=True)\n",
    "\n",
    "# Save the testing set as JSON\n",
    "test_set.to_json('Flares-dataset/5w1h_subtarea_1_train_test.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Prompt template for fine-tuning LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Create a Prompt with List-Type Output:\n",
    "\n",
    "[en rueda de prensa en la Moncloa, WHERE]\n",
    "\n",
    "[a España, WHO]\n",
    "\n",
    "[entre abril y septiembre, WHEN]\n",
    "\n",
    "[un total de 87 millones de vacunas, WHAT]\n",
    "\n",
    "[las mentiras, WHAT]\n",
    "\n",
    "[de Sánchez, WHO]\n",
    "\n",
    "[ese refrán que dice, WHAT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Con ejemplo en formato de lista\n",
    "def format_data_zero(df):\n",
    "    formatted_data = []  # List to hold the formatted dictionaries\n",
    "\n",
    "    instruction = (\"Analiza el texto y extrae fragmentos significativos, asignando a cada uno la etiqueta más \"\n",
    "                   \"adecuada según el tipo de información que representan en formato JSON. Las categorías de etiquetado son las siguientes:\"\n",
    "                   \"\\n\\nWHO: Sujetos o entidades involucradas.\\nWHAT: Hechos u objetos mencionados.\\nWHEN: Detalles relacionados con el tiempo.\\n\"\n",
    "                   \"WHERE: Lugares mencionados.\\nWHY: Causas o razones.\\nHOW: Maneras o métodos descritos.\"\n",
    "                   \"WHY (para causas o razones), y HOW (para maneras o métodos descritos).\"\n",
    "                   \"\\n\\n### Ejemplo:\\nTexto: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, \"\n",
    "                   \"entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que \"\n",
    "                   \"“la mentira tiene las patas muy cortas”.\\nFormato [Texto, Etiqueta]:\\n\"\n",
    "                   \"[en rueda de prensa en la Moncloa, WHERE]\\n[a España, WHO]\\n[entre abril y septiembre, WHEN]\\n[un total de 87 millones de vacunas, WHAT]\"\n",
    "                   \"\\n[las mentiras, WHAT]\\n[de Sánchez, WHO]\\n[ese refrán que dice, WHAT]\\n\\n### Texto:\\n\"\"\")\n",
    "\n",
    "    for i in range(len(df['Text'])):\n",
    "        # Constructing the 'input' part with instruction\n",
    "        input_text = instruction + df['Text'][i]\n",
    "        \n",
    "        # Initializing the 'output' part\n",
    "        output_text = ''\n",
    "        \n",
    "        # Loop through each tag and append the extracted text and 5W1H label to 'output'\n",
    "        for tag in df['Tags'][i]:\n",
    "            extracted_text = input_text[tag['Tag_Start'] + len(instruction):tag['Tag_End'] + len(instruction)]\n",
    "            output_text += f\"[{extracted_text}, {tag['5W1H_Label']}]\\n\"\n",
    "        \n",
    "        # Remove the last newline and space\n",
    "        output_text = output_text.rstrip('\\n ')\n",
    "        \n",
    "        # Append the formatted dictionary to the list\n",
    "        formatted_data.append({'input': input_text, 'output': output_text})\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create a Prompt with JSON Output (json_format1):\n",
    "\n",
    "{'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Con ejemplo y en formato JSON\n",
    "def format_data_zero(df):\n",
    "    formatted_data = []  # List to hold the formatted dictionaries\n",
    "\n",
    "    instruction = (\"Tu tarea consiste en analizar el texto proporcionado y extraer fragmentos significativos, \"\n",
    "                   \"transcribiéndolos exactamente como aparecen. Asigna a cada fragmento la etiqueta \"\n",
    "                   \"correspondiente basada en la información que representa. Presenta los resultados en formato JSON. Las categorías de etiquetado son:\"\n",
    "                   \"\\n\\nWHO: Sujetos o entidades involucradas.\\nWHAT: Hechos u objetos mencionados.\\nWHEN: Detalles relacionados con el tiempo.\\n\"\n",
    "                   \"WHERE: Lugares mencionados.\\nWHY: Causas o razones.\\nHOW: Maneras o métodos descritos.\"\n",
    "                   \"\\n\\nAbajo es un ejemplo:\\n\\nInput: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, \"\n",
    "                   \"entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que \"\n",
    "                   \"“la mentira tiene las patas muy cortas”. Output: \"\n",
    "                   \"{'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], \"\n",
    "                   \"'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}\\n\\nAhora, completa la siguiente tarea:\\n\\nInput: \")\n",
    "\n",
    "    for i in range(len(df['Text'])):\n",
    "        # Constructing the 'input' part with instruction\n",
    "        input_text = instruction + df['Text'][i]\n",
    "        \n",
    "        # Initializing the 'output' part as a dictionary\n",
    "        output_dict = {}\n",
    "        \n",
    "        # Loop through each tag and append the extracted text and 5W1H label to 'output'\n",
    "        for tag in df['Tags'][i]:\n",
    "            extracted_text = input_text[tag['Tag_Start'] + len(instruction):tag['Tag_End'] + len(instruction)]\n",
    "            if tag['5W1H_Label'] not in output_dict:\n",
    "                output_dict[tag['5W1H_Label']] = []\n",
    "            output_dict[tag['5W1H_Label']].append(extracted_text)\n",
    "        \n",
    "        # Append the formatted dictionary to the list\n",
    "        formatted_data.append({'input': input_text, 'output': output_dict, 'tags':df['Tags'][i], 'Id':int(df['Id'][i])})\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Create a Prompt with JSON Output without example (json_format2):\n",
    "We are goign to use the instruction, input and response format.\n",
    "\n",
    "{'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sin ejemplo y en formato JSON\n",
    "def format_data_zero(df):\n",
    "    formatted_data = []  # List to hold the formatted dictionaries\n",
    "    \n",
    "    instruction = \"\"\"### Instruction:\n",
    "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
    "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
    "Los resultados deben ser presentados en formato JSON.\n",
    "\n",
    "Categorías de Etiquetado\n",
    "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
    "\n",
    "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
    "\n",
    "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
    "involucrados o mencionados en el texto.\n",
    "\n",
    "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
    "\n",
    "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
    "\n",
    "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
    "\n",
    "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
    "se realizan o suceden las cosas.\n",
    "\n",
    "### Input:\n",
    "\"\"\"\n",
    "    \n",
    "    for i in range(len(df['Text'])):\n",
    "        # Constructing the 'input' part with instruction\n",
    "        input_text = instruction + df['Text'][i]\n",
    "        \n",
    "        # Initializing the 'output' part as a dictionary\n",
    "        output_dict = {}\n",
    "        \n",
    "        # Loop through each tag and append the extracted text and 5W1H label to 'output'\n",
    "        for tag in df['Tags'][i]:\n",
    "            extracted_text = input_text[tag['Tag_Start'] + len(instruction):tag['Tag_End'] + len(instruction)]\n",
    "            if tag['5W1H_Label'] not in output_dict:\n",
    "                output_dict[tag['5W1H_Label']] = []\n",
    "            output_dict[tag['5W1H_Label']].append(extracted_text)\n",
    "        \n",
    "        # Append the formatted dictionary to the list\n",
    "        formatted_data.append({'input': input_text, 'output': output_dict, 'tags':df['Tags'][i], 'Id':int(df['Id'][i])})\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Create a Prompt with JSON Output without example (json_format2) SPANISH:\n",
    "We are goign to use the instruction, input and response format.\n",
    "\n",
    "{'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sin ejemplo y en formato JSON\n",
    "def format_data_zero(df):\n",
    "    formatted_data = []  # List to hold the formatted dictionaries\n",
    "    \n",
    "    instruction = \"\"\"A continuación, se presenta una instrucción que describe una tarea, junto con una entrada que proporciona contexto adicional. Escribe una respuesta que complete adecuadamente la solicitud.\n",
    "\n",
    "### Instrucciones:\n",
    "Tu tarea es analizar el texto proporcionado y extraer fragmentos que pertenezcan a las categorías específicas, asegurándote de que los fragmentos sean secuencias continuas de palabras exactamente como aparecen en el texto, sin reordenamientos ni omisiones.\n",
    "\n",
    "1. Leer el Texto Completo:\n",
    "Comprende el contenido general y el contexto del texto dado. Asegúrate de entender los principales eventos, descripciones, y entidades mencionadas.\n",
    "\n",
    "2. Extraer Fragmentos Relevantes:\n",
    "Identifica y extrae partes del texto que corresponden a cada una de las siguientes categorías. Los fragmentos deben ser exactos y no alterados del texto original.\n",
    "\n",
    "3. Clasificar cada Fragmento:\n",
    "Utiliza las categorías predefinidas para anotar cada fragmento extraído. Asegúrate de que la clasificación sea precisa según la definición de cada categoría.\n",
    "\n",
    "Categorías:\n",
    "\n",
    "WHAT (Qué): Hechos, objetos, o cualquier elemento concreto mencionado.\n",
    "WHO (Quién): Sujetos o entidades (personas, organizaciones, etc.) mencionados.\n",
    "WHEN (Cuándo): Momentos o periodos de tiempo especificados.\n",
    "WHERE (Dónde): Lugares, espacios geográficos o direcciones.\n",
    "WHY (Por qué): Causas, razones o motivaciones.\n",
    "HOW (Cómo): Maneras, métodos o procedimientos detallados.\n",
    "\n",
    "### Información de Entrada:\n",
    "\"\"\"\n",
    "    \n",
    "    for i in range(len(df['Text'])):\n",
    "        # Constructing the 'input' part with instruction\n",
    "        input_text = instruction + df['Text'][i]\n",
    "        \n",
    "        # Initializing the 'output' part as a dictionary\n",
    "        output_dict = {}\n",
    "        \n",
    "        # Loop through each tag and append the extracted text and 5W1H label to 'output'\n",
    "        for tag in df['Tags'][i]:\n",
    "            extracted_text = input_text[tag['Tag_Start'] + len(instruction):tag['Tag_End'] + len(instruction)]\n",
    "            if tag['5W1H_Label'] not in output_dict:\n",
    "                output_dict[tag['5W1H_Label']] = []\n",
    "            output_dict[tag['5W1H_Label']].append(extracted_text)\n",
    "        \n",
    "        # Append the formatted dictionary to the list\n",
    "        formatted_data.append({'input': input_text, 'output': output_dict, 'tags':df['Tags'][i], 'Id':int(df['Id'][i])})\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Prompt with JSON Output without example (json_format2) SPANISH:\n",
    "We are goign to use the instruction, input and response format.\n",
    "\n",
    "{'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create training datasets with the prompt template format (train and trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "task1_train = pd.read_json('Flares-dataset/5w1h_subtarea_1_train.json', lines=True)\n",
    "task1_test = pd.read_json('Flares-dataset/5w1h_subtask_1_trial.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt following the prompt template\n",
    "task1_zero_train = format_data_zero(task1_train)\n",
    "task1_zero_test = format_data_zero(task1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'output', 'tags', 'Id'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the file path where you want to save the JSON data\n",
    "file_path = 'data_files/5w1h_subtask_1_zero_train_json_format1.json'\n",
    "\n",
    "# Save the `formatted_data` as a JSON file\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(task1_zero_train, f, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the file path where you want to save the JSON data\n",
    "file_path = 'data_files/5w1h_subtask_1_zero_test_json_format1.json'\n",
    "\n",
    "# Save the `formatted_data` as a JSON file\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(task1_zero_test, f, indent=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dataset content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_zero_test = pd.read_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instrucciones:\n",
      "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
      "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
      "Los resultados deben ser presentados en formato JSON.\n",
      "\n",
      "Categorías de Etiquetado\n",
      "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
      "\n",
      "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
      "\n",
      "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
      "involucrados o mencionados en el texto.\n",
      "\n",
      "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
      "\n",
      "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
      "\n",
      "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
      "\n",
      "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
      "se realizan o suceden las cosas.\n",
      "\n",
      "### Información de Entrada:\n",
      "En cuanto a la incidencia acumulada, vuelve a subir, y se sitúa en los 255,55 casos por cada 100.000 habitantes, mientras que ayer, lunes 28 de diciembre de 2020, era de 246,19.\n"
     ]
    }
   ],
   "source": [
    "print(task1_zero_test['input'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WHAT': ['la incidencia acumulada'],\n",
       " 'WHERE': ['en los 255,55 casos por cada 100.000 habitantes'],\n",
       " 'WHEN': ['ayer, lunes 28 de diciembre de 2020']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_test['output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Tag_Start': 12,\n",
       "  'Tag_End': 35,\n",
       "  '5W1H_Label': 'WHAT',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'la incidencia acumulada'},\n",
       " {'Tag_Start': 64,\n",
       "  'Tag_End': 111,\n",
       "  '5W1H_Label': 'WHERE',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'en los 255,55 casos por cada 100.000 habitantes'},\n",
       " {'Tag_Start': 126,\n",
       "  'Tag_End': 161,\n",
       "  '5W1H_Label': 'WHEN',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'ayer, lunes 28 de diciembre de 2020'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_test['tags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instrucciones:\n",
      "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
      "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
      "Los resultados deben ser presentados en formato JSON.\n",
      "\n",
      "Categorías de Etiquetado\n",
      "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
      "\n",
      "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
      "\n",
      "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
      "involucrados o mencionados en el texto.\n",
      "\n",
      "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
      "\n",
      "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
      "\n",
      "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
      "\n",
      "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
      "se realizan o suceden las cosas.\n",
      "\n",
      "### Información de Entrada:\n",
      "La doctora Margarite Griesz-Brisson es una especialista alemana en neurofisiología y neurotoxicología. \n"
     ]
    }
   ],
   "source": [
    "print(task1_zero_test['input'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WHO': ['La doctora Margarite Griesz-Brisson'],\n",
       " 'WHAT': ['una especialista alemana en neurofisiología y neurotoxicología']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_test['output'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Tag_Start': 0,\n",
       "  'Tag_End': 35,\n",
       "  '5W1H_Label': 'WHO',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'La doctora Margarite Griesz-Brisson'},\n",
       " {'Tag_Start': 39,\n",
       "  'Tag_End': 101,\n",
       "  '5W1H_Label': 'WHAT',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'una especialista alemana en neurofisiología y neurotoxicología'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_test['tags'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instrucciones:\n",
      "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
      "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
      "Los resultados deben ser presentados en formato JSON.\n",
      "\n",
      "Categorías de Etiquetado\n",
      "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
      "\n",
      "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
      "\n",
      "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
      "involucrados o mencionados en el texto.\n",
      "\n",
      "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
      "\n",
      "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
      "\n",
      "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
      "\n",
      "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
      "se realizan o suceden las cosas.\n",
      "\n",
      "### Información de Entrada:\n",
      "Los síntomas de alerta agudos son dolores de cabeza, somnolencia, mareos, problemas de concentración y tiempo de reacción retardado, que son reacciones del sistema cognitivo.\n"
     ]
    }
   ],
   "source": [
    "print(task1_zero_test['input'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WHAT': ['Los síntomas de alerta agudos',\n",
       "  'dolores de cabeza, somnolencia, mareos, problemas de concentración y tiempo de reacción retardado, que son reacciones del sistema cognitivo']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_test['output'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Tag_Start': 0,\n",
       "  'Tag_End': 29,\n",
       "  '5W1H_Label': 'WHAT',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'Los síntomas de alerta agudos'},\n",
       " {'Tag_Start': 34,\n",
       "  'Tag_End': 173,\n",
       "  '5W1H_Label': 'WHAT',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'dolores de cabeza, somnolencia, mareos, problemas de concentración y tiempo de reacción retardado, que son reacciones del sistema cognitivo'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_test['tags'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Create honest training dataset (train split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load split train\n",
    "task1_train = pd.read_json('Flares-dataset/5w1h_subtarea_1_train_train.json', lines=True)\n",
    "task1_test = pd.read_json('Flares-dataset/5w1h_subtarea_1_train_test.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601    Esta es una molécula de señalización inmunitaria asociada con una reacción inmune exagerada, la denominada «tormenta de citocinas».\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_train[task1_train['Id'] == 1008]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El experto ha acompañado el mensaje con una fotografía de uno de los casos observados, en el que se ve una lengua manchada o descolorida.\\xa0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_test['Text'][250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_zero_train = format_data_zero(task1_train)\n",
    "task1_zero_test = format_data_zero(task1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'output', 'tags', 'Id'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(\"data_files/json_format2_spanish\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the file path where you want to save the JSON data\n",
    "file_path = 'data_files/json_format2_spanish/5w1h_subtask_1_zero_train_train_json_format2_spanish.json'\n",
    "\n",
    "# Save the `formatted_data` as a JSON file\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(task1_zero_train, f, ensure_ascii = False, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the file path where you want to save the JSON data\n",
    "file_path = 'data_files/json_format2_spanish/5w1h_subtask_1_zero_train_test_json_format2_spanish.json'\n",
    "\n",
    "# Save the `formatted_data` as a JSON file\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(task1_zero_test, f, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_zero_train = pd.read_json('data_files/json_format2_spanish/5w1h_subtask_1_zero_train_train_json_format2_spanish.json')\n",
    "task1_zero_test = pd.read_json('data_files/json_format2_spanish/5w1h_subtask_1_zero_train_test_json_format2_spanish.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1268, 4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>A continuación, se presenta una instrucción que describe una tarea, junto con una entrada que proporciona contexto adicional. Escribe una respuesta que complete adecuadamente la solicitud.\\n\\n### Instrucciones:\\nTu tarea es analizar el texto proporcionado y extraer fragmentos que pertenezcan a las categorías específicas, asegurándote de que los fragmentos sean secuencias continuas de palabras exactamente como aparecen en el texto, sin reordenamientos ni omisiones.\\n\\n1. Leer el Texto Completo:\\nComprende el contenido general y el contexto del texto dado. Asegúrate de entender los principales eventos, descripciones, y entidades mencionadas.\\n\\n2. Extraer Fragmentos Relevantes:\\nIdentifica y extrae partes del texto que corresponden a cada una de las siguientes categorías. Los fragmentos deben ser exactos y no alterados del texto original.\\n\\n3. Clasificar cada Fragmento:\\nUtiliza las categorías predefinidas para anotar cada fragmento extraído. Asegúrate de que la clasificación sea precisa según la definición de cada categoría.\\n\\nCategorías:\\n\\nWHAT (Qué): Hechos, objetos, o cualquier elemento concreto mencionado.\\nWHO (Quién): Sujetos o entidades (personas, organizaciones, etc.) mencionados.\\nWHEN (Cuándo): Momentos o periodos de tiempo especificados.\\nWHERE (Dónde): Lugares, espacios geográficos o direcciones.\\nWHY (Por qué): Causas, razones o motivaciones.\\nHOW (Cómo): Maneras, métodos o procedimientos detallados.\\n\\n### Información de Entrada:\\nEl experto ha acompañado el mensaje con una fotografía de uno de los casos observados, en el que se ve una lengua manchada o descolorida.</td>\n",
       "      <td>{'WHO': ['El experto'], 'WHAT': ['el mensaje', 'una lengua manchada o descolorida'], 'HOW': ['con una fotografía de uno de los casos observados']}</td>\n",
       "      <td>[{'Tag_Start': 0, 'Tag_End': 10, '5W1H_Label': 'WHO', 'Reliability_Label': 'confiable', 'Tag_Text': 'El experto'}, {'Tag_Start': 25, 'Tag_End': 35, '5W1H_Label': 'WHAT', 'Reliability_Label': 'confiable', 'Tag_Text': 'el mensaje'}, {'Tag_Start': 36, 'Tag_End': 85, '5W1H_Label': 'HOW', 'Reliability_Label': 'semiconfiable', 'Tag_Text': 'con una fotografía de uno de los casos observados'}, {'Tag_Start': 103, 'Tag_End': 136, '5W1H_Label': 'WHAT', 'Reliability_Label': 'semiconfiable', 'Tag_Text': 'una lengua manchada o descolorida'}]</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         input  \\\n",
       "250  A continuación, se presenta una instrucción que describe una tarea, junto con una entrada que proporciona contexto adicional. Escribe una respuesta que complete adecuadamente la solicitud.\\n\\n### Instrucciones:\\nTu tarea es analizar el texto proporcionado y extraer fragmentos que pertenezcan a las categorías específicas, asegurándote de que los fragmentos sean secuencias continuas de palabras exactamente como aparecen en el texto, sin reordenamientos ni omisiones.\\n\\n1. Leer el Texto Completo:\\nComprende el contenido general y el contexto del texto dado. Asegúrate de entender los principales eventos, descripciones, y entidades mencionadas.\\n\\n2. Extraer Fragmentos Relevantes:\\nIdentifica y extrae partes del texto que corresponden a cada una de las siguientes categorías. Los fragmentos deben ser exactos y no alterados del texto original.\\n\\n3. Clasificar cada Fragmento:\\nUtiliza las categorías predefinidas para anotar cada fragmento extraído. Asegúrate de que la clasificación sea precisa según la definición de cada categoría.\\n\\nCategorías:\\n\\nWHAT (Qué): Hechos, objetos, o cualquier elemento concreto mencionado.\\nWHO (Quién): Sujetos o entidades (personas, organizaciones, etc.) mencionados.\\nWHEN (Cuándo): Momentos o periodos de tiempo especificados.\\nWHERE (Dónde): Lugares, espacios geográficos o direcciones.\\nWHY (Por qué): Causas, razones o motivaciones.\\nHOW (Cómo): Maneras, métodos o procedimientos detallados.\\n\\n### Información de Entrada:\\nEl experto ha acompañado el mensaje con una fotografía de uno de los casos observados, en el que se ve una lengua manchada o descolorida.    \n",
       "\n",
       "                                                                                                                                                 output  \\\n",
       "250  {'WHO': ['El experto'], 'WHAT': ['el mensaje', 'una lengua manchada o descolorida'], 'HOW': ['con una fotografía de uno de los casos observados']}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      tags  \\\n",
       "250  [{'Tag_Start': 0, 'Tag_End': 10, '5W1H_Label': 'WHO', 'Reliability_Label': 'confiable', 'Tag_Text': 'El experto'}, {'Tag_Start': 25, 'Tag_End': 35, '5W1H_Label': 'WHAT', 'Reliability_Label': 'confiable', 'Tag_Text': 'el mensaje'}, {'Tag_Start': 36, 'Tag_End': 85, '5W1H_Label': 'HOW', 'Reliability_Label': 'semiconfiable', 'Tag_Text': 'con una fotografía de uno de los casos observados'}, {'Tag_Start': 103, 'Tag_End': 136, '5W1H_Label': 'WHAT', 'Reliability_Label': 'semiconfiable', 'Tag_Text': 'una lengua manchada o descolorida'}]   \n",
       "\n",
       "      Id  \n",
       "250  956  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_test[task1_zero_test['Id'] == 956]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A continuación, se presenta una instrucción que describe una tarea, junto con una entrada que proporciona contexto adicional. Escribe una respuesta que complete adecuadamente la solicitud.\n",
      "\n",
      "### Instrucciones:\n",
      "Tu tarea es analizar el texto proporcionado y extraer fragmentos que pertenezcan a las categorías específicas, asegurándote de que los fragmentos sean secuencias continuas de palabras exactamente como aparecen en el texto, sin reordenamientos ni omisiones.\n",
      "\n",
      "1. Leer el Texto Completo:\n",
      "Comprende el contenido general y el contexto del texto dado. Asegúrate de entender los principales eventos, descripciones, y entidades mencionadas.\n",
      "\n",
      "2. Extraer Fragmentos Relevantes:\n",
      "Identifica y extrae partes del texto que corresponden a cada una de las siguientes categorías. Los fragmentos deben ser exactos y no alterados del texto original.\n",
      "\n",
      "3. Clasificar cada Fragmento:\n",
      "Utiliza las categorías predefinidas para anotar cada fragmento extraído. Asegúrate de que la clasificación sea precisa según la definición de cada categoría.\n",
      "\n",
      "Categorías:\n",
      "\n",
      "WHAT (Qué): Hechos, objetos, o cualquier elemento concreto mencionado.\n",
      "WHO (Quién): Sujetos o entidades (personas, organizaciones, etc.) mencionados.\n",
      "WHEN (Cuándo): Momentos o periodos de tiempo especificados.\n",
      "WHERE (Dónde): Lugares, espacios geográficos o direcciones.\n",
      "WHY (Por qué): Causas, razones o motivaciones.\n",
      "HOW (Cómo): Maneras, métodos o procedimientos detallados.\n",
      "\n",
      "### Información de Entrada:\n",
      "Y es que según informa el digital OK Diario, en un artículo que puedes leer en este enlace, el Gobierno de España ha subvencionado con 45.980 euros un estudio sobre el impacto sexista de los piropos.\n"
     ]
    }
   ],
   "source": [
    "print(task1_zero_train['input'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WHO': ['el digital OK Diario', 'el Gobierno de España'],\n",
       " 'WHERE': ['en un artículo que puedes leer en este enlace'],\n",
       " 'HOW': ['con 45.980 euros'],\n",
       " 'WHAT': ['un estudio sobre el impacto sexista de los piropos']}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_train['output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Tag_Start': 23,\n",
       "  'Tag_End': 43,\n",
       "  '5W1H_Label': 'WHO',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'el digital OK Diario'},\n",
       " {'Tag_Start': 45,\n",
       "  'Tag_End': 90,\n",
       "  '5W1H_Label': 'WHERE',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'en un artículo que puedes leer en este enlace'},\n",
       " {'Tag_Start': 92,\n",
       "  'Tag_End': 113,\n",
       "  '5W1H_Label': 'WHO',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'el Gobierno de España'},\n",
       " {'Tag_Start': 131,\n",
       "  'Tag_End': 147,\n",
       "  '5W1H_Label': 'HOW',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'con 45.980 euros'},\n",
       " {'Tag_Start': 148,\n",
       "  'Tag_End': 198,\n",
       "  '5W1H_Label': 'WHAT',\n",
       "  'Reliability_Label': 'semiconfiable',\n",
       "  'Tag_Text': 'un estudio sobre el impacto sexista de los piropos'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_train['tags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1382\n",
       "1       553\n",
       "2       567\n",
       "3       483\n",
       "4       938\n",
       "       ... \n",
       "312    1447\n",
       "313     583\n",
       "314     766\n",
       "315    1097\n",
       "316     789\n",
       "Name: Id, Length: 317, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A continuación, se presenta una instrucción que describe una tarea, junto con una entrada que proporciona contexto adicional. Escribe una respuesta que complete adecuadamente la solicitud.\n",
      "\n",
      "### Instrucciones:\n",
      "Tu tarea es analizar el texto proporcionado y extraer fragmentos que pertenezcan a las categorías específicas, asegurándote de que los fragmentos sean secuencias continuas de palabras exactamente como aparecen en el texto, sin reordenamientos ni omisiones.\n",
      "\n",
      "1. Leer el Texto Completo:\n",
      "Comprende el contenido general y el contexto del texto dado. Asegúrate de entender los principales eventos, descripciones, y entidades mencionadas.\n",
      "\n",
      "2. Extraer Fragmentos Relevantes:\n",
      "Identifica y extrae partes del texto que corresponden a cada una de las siguientes categorías. Los fragmentos deben ser exactos y no alterados del texto original.\n",
      "\n",
      "3. Clasificar cada Fragmento:\n",
      "Utiliza las categorías predefinidas para anotar cada fragmento extraído. Asegúrate de que la clasificación sea precisa según la definición de cada categoría.\n",
      "\n",
      "Categorías:\n",
      "\n",
      "WHAT (Qué): Hechos, objetos, o cualquier elemento concreto mencionado.\n",
      "WHO (Quién): Sujetos o entidades (personas, organizaciones, etc.) mencionados.\n",
      "WHEN (Cuándo): Momentos o periodos de tiempo especificados.\n",
      "WHERE (Dónde): Lugares, espacios geográficos o direcciones.\n",
      "WHY (Por qué): Causas, razones o motivaciones.\n",
      "HOW (Cómo): Maneras, métodos o procedimientos detallados.\n",
      "\n",
      "### Información de Entrada:\n",
      "Se trata de una sustancia soluble en agua que se forma al cocinar alimentos ricos en hidratos de carbono -como cereales o patatas- a temperaturas superiores a 120 grados y en ambientes de baja humedad, sobre todo cuando freímos, tostamos u horneamos. \n"
     ]
    }
   ],
   "source": [
    "print(task1_zero_train['input'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WHAT': ['una sustancia soluble'],\n",
       " 'WHERE': ['en agua', 'en ambientes de baja humedad'],\n",
       " 'HOW': ['al cocinar alimentos ricos en hidratos de carbono -como cereales o patatas- a temperaturas superiores a 120 grados'],\n",
       " 'WHEN': ['cuando freímos, tostamos u horneamos']}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_train['output'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Tag_Start': 12,\n",
       "  'Tag_End': 33,\n",
       "  '5W1H_Label': 'WHAT',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'una sustancia soluble'},\n",
       " {'Tag_Start': 34,\n",
       "  'Tag_End': 41,\n",
       "  '5W1H_Label': 'WHERE',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'en agua'},\n",
       " {'Tag_Start': 55,\n",
       "  'Tag_End': 169,\n",
       "  '5W1H_Label': 'HOW',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'al cocinar alimentos ricos en hidratos de carbono -como cereales o patatas- a temperaturas superiores a 120 grados'},\n",
       " {'Tag_Start': 172,\n",
       "  'Tag_End': 200,\n",
       "  '5W1H_Label': 'WHERE',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'en ambientes de baja humedad'},\n",
       " {'Tag_Start': 213,\n",
       "  'Tag_End': 249,\n",
       "  '5W1H_Label': 'WHEN',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'cuando freímos, tostamos u horneamos'}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_train['tags'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A continuación, se presenta una instrucción que describe una tarea, junto con una entrada que proporciona contexto adicional. Escribe una respuesta que complete adecuadamente la solicitud.\n",
      "\n",
      "### Instrucciones:\n",
      "Tu tarea es analizar el texto proporcionado y extraer fragmentos que pertenezcan a las categorías específicas, asegurándote de que los fragmentos sean secuencias continuas de palabras exactamente como aparecen en el texto, sin reordenamientos ni omisiones.\n",
      "\n",
      "1. Leer el Texto Completo:\n",
      "Comprende el contenido general y el contexto del texto dado. Asegúrate de entender los principales eventos, descripciones, y entidades mencionadas.\n",
      "\n",
      "2. Extraer Fragmentos Relevantes:\n",
      "Identifica y extrae partes del texto que corresponden a cada una de las siguientes categorías. Los fragmentos deben ser exactos y no alterados del texto original.\n",
      "\n",
      "3. Clasificar cada Fragmento:\n",
      "Utiliza las categorías predefinidas para anotar cada fragmento extraído. Asegúrate de que la clasificación sea precisa según la definición de cada categoría.\n",
      "\n",
      "Categorías:\n",
      "\n",
      "WHAT (Qué): Hechos, objetos, o cualquier elemento concreto mencionado.\n",
      "WHO (Quién): Sujetos o entidades (personas, organizaciones, etc.) mencionados.\n",
      "WHEN (Cuándo): Momentos o periodos de tiempo especificados.\n",
      "WHERE (Dónde): Lugares, espacios geográficos o direcciones.\n",
      "WHY (Por qué): Causas, razones o motivaciones.\n",
      "HOW (Cómo): Maneras, métodos o procedimientos detallados.\n",
      "\n",
      "### Información de Entrada:\n",
      "“Es muy importante seguir estas normas, dado que nosotros estamos en un momento muy especial, conteniendo y trabajando fuertemente para la contención de los diferentes linajes o cepas que está presentando el mundo”, concluyó el Ministro de Salud.\n"
     ]
    }
   ],
   "source": [
    "print(task1_zero_train['input'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WHO': ['el Ministro de Salud']}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_train['output'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Tag_Start': 225,\n",
       "  'Tag_End': 245,\n",
       "  '5W1H_Label': 'WHO',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_Text': 'el Ministro de Salud'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_zero_train['tags'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create a Prompt with JSON Output (json_format1):\n",
    "\n",
    "{'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Con ejemplo y en formato JSON\n",
    "def format_data_zero(df):\n",
    "    formatted_data = []  # List to hold the formatted dictionaries\n",
    "\n",
    "    instruction = (\"Tu tarea consiste en analizar el texto proporcionado y extraer fragmentos significativos, \"\n",
    "                   \"transcribiéndolos exactamente como aparecen. Asigna a cada fragmento la etiqueta \"\n",
    "                   \"correspondiente basada en la información que representa. Presenta los resultados en formato JSON. Las categorías de etiquetado son:\"\n",
    "                   \"\\n\\nWHO: Sujetos o entidades involucradas.\\nWHAT: Hechos u objetos mencionados.\\nWHEN: Detalles relacionados con el tiempo.\\n\"\n",
    "                   \"WHERE: Lugares mencionados.\\nWHY: Causas o razones.\\nHOW: Maneras o métodos descritos.\"\n",
    "                   \"\\n\\nAbajo es un ejemplo:\\n\\nInput: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, \"\n",
    "                   \"entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que \"\n",
    "                   \"“la mentira tiene las patas muy cortas”. Output: \"\n",
    "                   \"{'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], \"\n",
    "                   \"'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}\\n\\nAhora, completa la siguiente tarea:\\n\\nInput: \")\n",
    "\n",
    "    for i in range(len(df['Text'])):\n",
    "        # Constructing the 'input' part with instruction\n",
    "        input_text = instruction + df['Text'][i]\n",
    "        \n",
    "        # Append the formatted dictionary to the list\n",
    "        formatted_data.append({'input': input_text, 'Id':int(df['Id'][i])})\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_test = pd.read_json('Flares-dataset/5w1h_subtarea_1_test.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(\"data_files/json_format1\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_zero_test = format_data_zero(task1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the file path where you want to save the JSON data\n",
    "file_path = 'data_files/json_format1/5w1h_subtask_1_test_json_format1.json'\n",
    "\n",
    "# Save the `formatted_data` as a JSON file\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(task1_zero_test, f, ensure_ascii = False, indent=4) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
