{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VC-9m2yv3m18"
   },
   "source": [
    "## Let's begin!\n",
    "Notebook based on brevdev notebook: https://github.com/brevdev/notebooks/blob/main/mistral-finetune-own-data.ipynb\n",
    "### 0. Preparing data\n",
    "\n",
    "Before you check out a GPU, prepare your dataset for loading and training.\n",
    "\n",
    "To prepare your dataset for loading, all you need are two `.jsonl` files structured something like this:\n",
    "```\n",
    "{\"input\": \"What color is the sky?\", \"output\": \"The sky is blue.\"}\n",
    "{\"input\": \"Where is the best place to get cloud GPUs?\", \"output\": \"Brev.dev\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2CkxsA43m15"
   },
   "source": [
    "### 1. Instantiate GPU & Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FuXIFTFapAMI",
    "outputId": "c8ced1ad-c7b3-44ba-807b-26d7d13906bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# You only need to run this once per machine\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U transformers\n",
    "!pip install -q -U peft\n",
    "!pip install -q -U accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "s6f4z8EYmcJ6"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='../data_files/5w1h_subtask_1_zero_train_json_format1.json', encoding = 'utf-8',split='train')\n",
    "eval_dataset = load_dataset('json', data_files='../data_files/5w1h_subtask_1_zero_train_json_format1.json', encoding = 'utf-8', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tags': [{'5W1H_Label': 'WHERE',\n",
       "   'Reliability_Label': 'confiable',\n",
       "   'Tag_End': 26,\n",
       "   'Tag_Start': 0,\n",
       "   'Tag_Text': 'En la Comunidad Valenciana'},\n",
       "  {'5W1H_Label': 'WHO',\n",
       "   'Reliability_Label': 'confiable',\n",
       "   'Tag_End': 46,\n",
       "   'Tag_Start': 28,\n",
       "   'Tag_Text': 'algunos consellers'},\n",
       "  {'5W1H_Label': 'WHAT',\n",
       "   'Reliability_Label': 'confiable',\n",
       "   'Tag_End': 77,\n",
       "   'Tag_Start': 61,\n",
       "   'Tag_Text': 'esta alternativa'},\n",
       "  {'5W1H_Label': 'WHEN',\n",
       "   'Reliability_Label': 'confiable',\n",
       "   'Tag_End': 91,\n",
       "   'Tag_Start': 78,\n",
       "   'Tag_Text': 'el 5 de enero'},\n",
       "  {'5W1H_Label': 'WHO',\n",
       "   'Reliability_Label': 'confiable',\n",
       "   'Tag_End': 260,\n",
       "   'Tag_Start': 202,\n",
       "   'Tag_Text': 'la vicepresidenta portavoz de la Generalitat, Mónica Oltra'}],\n",
       " 'input': \"Tu tarea consiste en analizar el texto proporcionado y extraer fragmentos significativos, transcribiéndolos exactamente como aparecen. Asigna a cada fragmento la etiqueta correspondiente basada en la información que representa. Presenta los resultados en formato JSON. Las categorías de etiquetado son:\\n\\nWHO: Sujetos o entidades involucradas.\\nWHAT: Hechos u objetos mencionados.\\nWHEN: Detalles relacionados con el tiempo.\\nWHERE: Lugares mencionados.\\nWHY: Causas o razones.\\nHOW: Maneras o métodos descritos.\\n\\nAbajo es un ejemplo:\\n\\nInput: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que “la mentira tiene las patas muy cortas”. Output: {'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}\\n\\nAhora, completa la siguiente tarea:\\n\\nInput: En la Comunidad Valenciana, algunos consellers ya plantearon esta alternativa el 5 de enero, aunque «finalmente no se consideró que fuera algo que en este momento se tuviera que hacer», según reconoció la vicepresidenta portavoz de la Generalitat, Mónica Oltra.\",\n",
       " 'Id': 1464,\n",
       " 'output': {'HOW': None,\n",
       "  'WHAT': ['esta alternativa'],\n",
       "  'WHEN': ['el 5 de enero'],\n",
       "  'WHERE': ['En la Comunidad Valenciana'],\n",
       "  'WHO': ['algunos consellers',\n",
       "   'la vicepresidenta portavoz de la Generalitat, Mónica Oltra'],\n",
       "  'WHY': None}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[306]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05H5MIfjyRgc"
   },
   "source": [
    "### Accelerator\n",
    "\n",
    "Set up the Accelerator ([description](https://huggingface.co/docs/accelerate/v0.19.0/en/usage_guides/fsdp))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TEzYBadkyRgd"
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9KNTJZkyRgn"
   },
   "source": [
    "\n",
    "Let's use Weights & Biases to track our training metrics. You'll need to apply an API key when prompted. Feel free to skip this if you'd like, and just comment out the `wandb` parameters in the `Trainer` definition below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDqUNyIoyRgo"
   },
   "outputs": [],
   "source": [
    "!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"Flares-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhw8JiOr3m18"
   },
   "source": [
    "### Formatting prompts\n",
    "Then create a `formatting_func` to structure training examples as prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f-fJR0MlQiTD"
   },
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"{example['input']} Output: {example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sflV0DL2P64_"
   },
   "source": [
    "Here's another common one:\n",
    "\n",
    "```python\n",
    "def formatting_func(example):\n",
    "    text = f\"{example['input']} Output: {example['output']}\"\n",
    "    return text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shz8Xdv-yRgf"
   },
   "source": [
    "### 2. Load Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ-5idQwzvg-"
   },
   "source": [
    "Let's now load Llama3 - meta-llama/Meta-Llama-3-8B - using 4-bit quantization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JupyterLab v3.4.6\n",
      "/opt/conda/share/jupyter/labextensions\n",
      "        jupyterlab_pygments v0.2.2 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, jupyterlab_pygments)\n",
      "        jupyter-matplotlib v0.11.2 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n",
      "        @jupyter-widgets/jupyterlab-manager v5.0.3 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, jupyterlab_widgets)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!jupyter labextension list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "45524c98039a46d5b7745ad7cb638d2f"
     ]
    },
    "id": "E0Nl5mWL0k2T",
    "outputId": "47b6b01d-e9f2-4b70-919c-17ae64993843"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4873d27106554952b6e24283152fb159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea480fd39eea48068fafa8c21b26753a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjNdXolqyRgf"
   },
   "source": [
    "### 3. Tokenization\n",
    "\n",
    "Set up the tokenizer. Add padding on the left as it [makes training use less memory](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa).\n",
    "\n",
    "\n",
    "For `model_max_length`, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "haSUDD9HyRgf",
    "outputId": "22ee95db-2974-4ab0-e0c7-444d04d3e838"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHnKLcq4yRgg"
   },
   "source": [
    "Reformat the prompt and tokenize each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "S3iLAwLh3m19"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ded0704df544038b6daf57bb7c258ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1585 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6ewk27p3m19"
   },
   "source": [
    "Let's get a distribution of our dataset lengths, so we can determine the appropriate `max_length` for our input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BA8M9yfC3m19",
    "outputId": "99c6d302-9bb6-47b1-cae9-a1cd870b4770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3170\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBk4Qp_vyRgh"
   },
   "source": [
    "From here, you can choose where you'd like to set the `max_length` to be. You can truncate and pad training examples to fit them to your chosen size. Be aware that choosing a larger `max_length` has its compute tradeoffs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMlw8h743m19"
   },
   "source": [
    "Now let's tokenize again with padding and truncation, and set up the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning is](https://neptune.ai/blog/self-supervised-learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "acINaViR3m19"
   },
   "outputs": [],
   "source": [
    "max_length = 700 # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "518d4f0b89bf4d57bf00d4c6d6e59eb5"
     ]
    },
    "id": "lTk-aTog3m19",
    "outputId": "4fb637b4-77a2-47c6-de7b-4fb620663dd7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1159ccd403cf478db203a5208746bd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1585 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a782c6e46a6e478f905da12ac8b8f405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1585 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQL796OayRgh"
   },
   "source": [
    "Check that `input_ids` is padded on the left with the `eos_token` (2) and there is an `eos_token` 2 added to the end, and the prompt starts with a `bos_token` (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OKHhvxK83m19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128000, 54071, 91007, 6824, 68, 665, 3260, 11403, 658, 33125, 80943, 2172, 379, 5066, 261, 12569, 437, 4698, 64545, 11, 1380, 745, 8385, 978, 303, 337, 437, 4839, 9157, 8112, 56270, 48422, 13, 1666, 625, 64, 264, 19394, 12569, 78, 1208, 62044, 1955, 8024, 13140, 3122, 2649, 665, 1208, 35615, 1744, 96215, 13, 27740, 64, 2537, 47822, 665, 55956, 4823, 13, 16132, 22824, 25318, 409, 62044, 295, 2172, 4538, 1473, 78847, 25, 328, 69007, 437, 297, 1218, 13910, 4457, 1791, 81, 11354, 627, 60960, 25, 1283, 46348, 577, 75148, 52618, 290, 5670, 627, 20484, 965, 25, 16828, 97029, 47105, 5670, 390, 658, 29842, 627, 27611, 25, 93590, 5518, 52618, 290, 5670, 627, 20484, 56, 25, 356, 12119, 300, 297, 24788, 3233, 627, 61297, 25, 2418, 9431, 297, 36252, 16790, 6697, 95112, 382, 5953, 19256, 1560, 653, 58300, 1473, 2566, 25, 58020, 46180, 11, 4839, 9157, 19538, 58516, 8924, 46180, 23553, 1744, 328, 99634, 9616, 66, 26919, 665, 436, 3340, 64, 409, 864, 4511, 64, 665, 1208, 3206, 33678, 64, 8136, 404, 80844, 1744, 264, 57608, 75883, 42550, 11, 9465, 88387, 379, 35429, 54571, 11, 653, 2860, 409, 220, 4044, 64124, 409, 9467, 59364, 3429, 74777, 437, 32195, 409, 1744, 5252, 11540, 51185, 409, 328, 99634, 92065, 93641, 42918, 19914, 11644, 1744, 22901, 1744, 1054, 4355, 11540, 9008, 24215, 5252, 3352, 300, 23321, 23100, 300, 11453, 9442, 25, 5473, 78847, 1232, 2570, 50, 99634, 518, 364, 64, 57608, 518, 364, 451, 328, 99634, 4181, 364, 27611, 1232, 2570, 268, 436, 3340, 64, 409, 864, 4511, 64, 665, 1208, 3206, 33678, 64, 4181, 364, 20484, 965, 1232, 2570, 40997, 88387, 379, 35429, 54571, 4181, 364, 60960, 1232, 2570, 359, 2860, 409, 220, 4044, 64124, 409, 9467, 59364, 518, 364, 14833, 11540, 51185, 518, 364, 2423, 19914, 11644, 1744, 22901, 663, 633, 25797, 6347, 11, 71301, 1208, 56001, 91007, 1473, 2566, 25, 56532, 2537, 4770, 18745, 912, 23363, 13055, 5339, 8968, 409, 1744, 1208, 25689, 2259, 41880, 5169, 658, 54698, 3427, 409, 17728, 269, 4193, 689, 665, 2537, 85024, 8952, 73258, 390, 20562, 12, 777, 13, 9442, 25, 5473, 61297, 1232, 2290, 11, 364, 60960, 1232, 2570, 68, 1325, 8968, 409, 1744, 1208, 25689, 2259, 41880, 5169, 658, 54698, 3427, 409, 17728, 269, 4193, 689, 4181, 364, 20484, 965, 1232, 2290, 11, 364, 27611, 1232, 2290, 11, 364, 78847, 1232, 2570, 2353, 4770, 18745, 518, 364, 268, 2537, 85024, 8952, 73258, 390, 20562, 12, 777, 4181, 364, 20484, 56, 1232, 2290, 92]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[2]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 09:55:38.468183: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-16 09:55:39.309967: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-16 09:55:41.707053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|begin_of_text|>Tu tarea consiste en analizar el texto proporcionado y extraer fragmentos significativos, transcribiéndolos exactamente como aparecen. Asigna a cada fragmento la etiqueta correspondiente basada en la información que representa. Presenta los resultados en formato JSON. Las categorías de etiquetado son:\n",
      "\n",
      "WHO: Sujetos o entidades involucradas.\n",
      "WHAT: Hechos u objetos mencionados.\n",
      "WHEN: Detalles relacionados con el tiempo.\n",
      "WHERE: Lugares mencionados.\n",
      "WHY: Causas o razones.\n",
      "HOW: Maneras o métodos descritos.\n",
      "\n",
      "Abajo es un ejemplo:\n",
      "\n",
      "Input: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que “la mentira tiene las patas muy cortas”. Output: {'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}\n",
      "\n",
      "Ahora, completa la siguiente tarea:\n",
      "\n",
      "Input: Pero los investigadores no encontraron evidencia de que la aspirina aumentara el riesgo de hemorragia en los pacientes hospitalizados con COVID-19. Output: {'HOW': None, 'WHAT': ['evidencia de que la aspirina aumentara el riesgo de hemorragia'], 'WHEN': None, 'WHERE': None, 'WHO': ['los investigadores', 'en los pacientes hospitalizados con COVID-19'], 'WHY': None}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_train_dataset[2]['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6LRa2Zm3m19"
   },
   "source": [
    "Now all the samples should be the same length, `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "I55Yo3yy3m19",
    "outputId": "c87e344d-e0f3-4542-afcc-4e2025926d64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3170\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tags', 'input', 'Id', 'output', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1585\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tu tarea consiste en analizar el texto proporcionado y extraer fragmentos significativos, transcribiéndolos exactamente como aparecen. Asigna a cada fragmento la etiqueta correspondiente basada en la información que representa. Presenta los resultados en formato JSON. Las categorías de etiquetado son:\n",
      "\n",
      "WHO: Sujetos o entidades involucradas.\n",
      "WHAT: Hechos u objetos mencionados.\n",
      "WHEN: Detalles relacionados con el tiempo.\n",
      "WHERE: Lugares mencionados.\n",
      "WHY: Causas o razones.\n",
      "HOW: Maneras o métodos descritos.\n",
      "\n",
      "Abajo es un ejemplo:\n",
      "\n",
      "Input: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que “la mentira tiene las patas muy cortas”. Output: {'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}\n",
      "\n",
      "Ahora, completa la siguiente tarea:\n",
      "\n",
      "Input: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que “la mentira tiene las patas muy cortas”.\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset['input'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HOW': None, 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice'], 'WHEN': ['entre abril y septiembre'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHY': None}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset['output'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128000, 54071, 91007, 6824, 68, 665, 3260, 11403, 658, 33125, 80943, 2172, 379, 5066, 261, 12569, 437, 4698, 64545, 11, 1380, 745, 8385, 978, 303, 337, 437, 4839, 9157, 8112, 56270, 48422, 13, 1666, 625, 64, 264, 19394, 12569, 78, 1208, 62044, 1955, 8024, 13140, 3122, 2649, 665, 1208, 35615, 1744, 96215, 13, 27740, 64, 2537, 47822, 665, 55956, 4823, 13, 16132, 22824, 25318, 409, 62044, 295, 2172, 4538, 1473, 78847, 25, 328, 69007, 437, 297, 1218, 13910, 4457, 1791, 81, 11354, 627, 60960, 25, 1283, 46348, 577, 75148, 52618, 290, 5670, 627, 20484, 965, 25, 16828, 97029, 47105, 5670, 390, 658, 29842, 627, 27611, 25, 93590, 5518, 52618, 290, 5670, 627, 20484, 56, 25, 356, 12119, 300, 297, 24788, 3233, 627, 61297, 25, 2418, 9431, 297, 36252, 16790, 6697, 95112, 382, 5953, 19256, 1560, 653, 58300, 1473, 2566, 25, 58020, 46180, 11, 4839, 9157, 19538, 58516, 8924, 46180, 23553, 1744, 328, 99634, 9616, 66, 26919, 665, 436, 3340, 64, 409, 864, 4511, 64, 665, 1208, 3206, 33678, 64, 8136, 404, 80844, 1744, 264, 57608, 75883, 42550, 11, 9465, 88387, 379, 35429, 54571, 11, 653, 2860, 409, 220, 4044, 64124, 409, 9467, 59364, 3429, 74777, 437, 32195, 409, 1744, 5252, 11540, 51185, 409, 328, 99634, 92065, 93641, 42918, 19914, 11644, 1744, 22901, 1744, 1054, 4355, 11540, 9008, 24215, 5252, 3352, 300, 23321, 23100, 300, 11453, 9442, 25, 5473, 78847, 1232, 2570, 50, 99634, 518, 364, 64, 57608, 518, 364, 451, 328, 99634, 4181, 364, 27611, 1232, 2570, 268, 436, 3340, 64, 409, 864, 4511, 64, 665, 1208, 3206, 33678, 64, 4181, 364, 20484, 965, 1232, 2570, 40997, 88387, 379, 35429, 54571, 4181, 364, 60960, 1232, 2570, 359, 2860, 409, 220, 4044, 64124, 409, 9467, 59364, 518, 364, 14833, 11540, 51185, 518, 364, 2423, 19914, 11644, 1744, 22901, 663, 633, 25797, 6347, 11, 71301, 1208, 56001, 91007, 1473, 2566, 25, 58020, 46180, 11, 4839, 9157, 19538, 58516, 8924, 46180, 23553, 1744, 328, 99634, 9616, 66, 26919, 665, 436, 3340, 64, 409, 864, 4511, 64, 665, 1208, 3206, 33678, 64, 8136, 404, 80844, 1744, 264, 57608, 75883, 42550, 11, 9465, 88387, 379, 35429, 54571, 11, 653, 2860, 409, 220, 4044, 64124, 409, 9467, 59364, 3429, 74777, 437, 32195, 409, 1744, 5252, 11540, 51185, 409, 328, 99634, 92065, 93641, 42918, 19914, 11644, 1744, 22901, 1744, 1054, 4355, 11540, 9008, 24215, 5252, 3352, 300, 23321, 23100, 300, 11453, 9442, 25, 5473, 61297, 1232, 2290, 11, 364, 60960, 1232, 2570, 359, 2860, 409, 220, 4044, 64124, 409, 9467, 59364, 518, 364, 14833, 11540, 51185, 518, 364, 2423, 19914, 11644, 1744, 22901, 4181, 364, 20484, 965, 1232, 2570, 40997, 88387, 379, 35429, 54571, 4181, 364, 27611, 1232, 2570, 268, 436, 3340, 64, 409, 864, 4511, 64, 665, 1208, 3206, 33678, 64, 4181, 364, 78847, 1232, 2570, 50, 99634, 518, 364, 64, 57608, 518, 364, 451, 328, 99634, 4181, 364, 20484, 56, 1232, 2290, 92]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|begin_of_text|>Tu tarea consiste en analizar el texto proporcionado y extraer fragmentos significativos, transcribiéndolos exactamente como aparecen. Asigna a cada fragmento la etiqueta correspondiente basada en la información que representa. Presenta los resultados en formato JSON. Las categorías de etiquetado son:\n",
      "\n",
      "WHO: Sujetos o entidades involucradas.\n",
      "WHAT: Hechos u objetos mencionados.\n",
      "WHEN: Detalles relacionados con el tiempo.\n",
      "WHERE: Lugares mencionados.\n",
      "WHY: Causas o razones.\n",
      "HOW: Maneras o métodos descritos.\n",
      "\n",
      "Abajo es un ejemplo:\n",
      "\n",
      "Input: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que “la mentira tiene las patas muy cortas”. Output: {'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}\n",
      "\n",
      "Ahora, completa la siguiente tarea:\n",
      "\n",
      "Input: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que “la mentira tiene las patas muy cortas”. Output: {'HOW': None, 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice'], 'WHEN': ['entre abril y septiembre'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHY': None}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_train_dataset['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jP3R4enP3m19"
   },
   "source": [
    "### How does the base model do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vxbl4ACsyRgi"
   },
   "source": [
    "Optionally, you can check how Mistral does on one of your data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gOxnx-cAyRgi"
   },
   "outputs": [],
   "source": [
    "eval_prompt = \"\"\"Tu tarea consiste en analizar el texto proporcionado y extraer fragmentos significativos, transcribiéndolos exactamente como aparecen. Asigna a cada fragmento la etiqueta correspondiente basada en la información que representa. Presenta los resultados en formato JSON. Las categorías de etiquetado son:\n",
    "\n",
    "WHO: Sujetos o entidades involucradas.\n",
    "WHAT: Hechos u objetos mencionados.\n",
    "WHEN: Detalles relacionados con el tiempo.\n",
    "WHERE: Lugares mencionados.\n",
    "WHY: Causas o razones.\n",
    "HOW: Maneras o métodos descritos.\n",
    "\n",
    "Abajo es un ejemplo:\n",
    "\n",
    "Input: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que “la mentira tiene las patas muy cortas”. Output: {'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}\n",
    "\n",
    "Ahora, completa la siguiente tarea:\n",
    "\n",
    "Input: Y es que según informa el digital OK Diario, en un artículo que puedes leer en este enlace, el Gobierno de España ha subvencionado con 45.980 euros un estudio sobre el impacto sexista de los piropos. Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NidIuFXMyRgi",
    "outputId": "b1794b11-9a22-4b0a-e871-7df039ab59fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tu tarea consiste en analizar el texto proporcionado y extraer fragmentos significativos, transcribiéndolos exactamente como aparecen. Asigna a cada fragmento la etiqueta correspondiente basada en la información que representa. Presenta los resultados en formato JSON. Las categorías de etiquetado son:\n",
      "\n",
      "WHO: Sujetos o entidades involucradas.\n",
      "WHAT: Hechos u objetos mencionados.\n",
      "WHEN: Detalles relacionados con el tiempo.\n",
      "WHERE: Lugares mencionados.\n",
      "WHY: Causas o razones.\n",
      "HOW: Maneras o métodos descritos.\n",
      "\n",
      "Abajo es un ejemplo:\n",
      "\n",
      "Input: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que “la mentira tiene las patas muy cortas”. Output: {'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}\n",
      "\n",
      "Ahora, completa la siguiente tarea:\n",
      "\n",
      "Input: Y es que según informa el digital OK Diario, en un artículo que puedes leer en este enlace, el Gobierno de España ha subvencionado con 45.980 euros un estudio sobre el impacto sexista de los piropos. Output:\n",
      "{'WHO': ['el Gobierno de España', 'el digital OK Diario', 'un estudio sobre el impacto sexista de los piropos'],\n",
      "'WHERE': [],\n",
      "'WHEN': ['según informa'],\n",
      "'WHAT': []}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=512, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HOW': ['con 45.980 euros'],\n",
       " 'WHAT': ['un estudio sobre el impacto sexista de los piropos'],\n",
       " 'WHEN': None,\n",
       " 'WHERE': ['en un artículo que puedes leer en este enlace'],\n",
       " 'WHO': ['el digital OK Diario', 'el Gobierno de España'],\n",
       " 'WHY': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'HOW': ['con 45.980 euros'], 'WHAT': ['un estudio sobre el impacto sexista de los piropos'], 'WHEN': None, 'WHERE': ['en un artículo que puedes leer en este enlace'], 'WHO': ['el digital OK Diario', 'el Gobierno de España'], 'WHY': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCAWeCzZyRgi"
   },
   "source": [
    "Observe how the model does out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AapDoyfAyRgi"
   },
   "source": [
    "### 4. Set Up LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp2gMi1ZzGET"
   },
   "source": [
    "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "a9EUEDAl0ss3"
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "gkIcwsSU01EB"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUYEpEK-yRgj"
   },
   "source": [
    "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`, and `lm_head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "XshGNsbxyRgj",
    "outputId": "c619b0e8-8516-4d4b-9abe-13eaa3f3b204",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear8bitLt(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6mTLuQJyRgj"
   },
   "source": [
    "Here we define the LoRA config.\n",
    "\n",
    "`r` is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
    "\n",
    "`alpha` is the scaling factor for the learned weights. The weight matrix is scaled by `alpha/r`, and thus a higher value for `alpha` assigns more weight to the LoRA activations.\n",
    "\n",
    "The values used in the QLoRA paper were `r=64` and `lora_alpha=16`, and these are said to generalize well, but we will use `r=32` and `lora_alpha=64` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Ybeyl20n3dYH",
    "outputId": "6a16c182-04d9-4812-ae81-502a8fe364d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 88121344 || all params: 8118382592 || trainable%: 1.0854544362917358\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_FHi_VLyRgn"
   },
   "source": [
    "See how the model looks different now, with the LoRA adapters added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "IaYMWak4yRgn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(128256, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaSdpaAttention(\n",
      "              (q_proj): lora.Linear8bitLt(\n",
      "                (base_layer): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear8bitLt(\n",
      "                (base_layer): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear8bitLt(\n",
      "                (base_layer): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear8bitLt(\n",
      "                (base_layer): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): lora.Linear8bitLt(\n",
      "                (base_layer): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear8bitLt(\n",
      "                (base_layer): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear8bitLt(\n",
      "                (base_layer): Linear8bitLt(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=128256, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=128256, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0MOtwf3zdZp"
   },
   "source": [
    "### 5. Run Training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEe0uWYSyRgo"
   },
   "source": [
    "Overfitting is when the validation loss goes up (bad) while the training loss goes down significantly, meaning the model is learning the training set really well, but is unable to generalize to new datapoints. In most cases, this is not desired.\n",
    "\n",
    "With that said, a note on training: you can set the `max_steps` to be high initially, and examine at what step your model's performance starts to degrade. There is where you'll find a sweet spot for how many steps to perform. For example, say you start with 1000 steps, and find that at around 500 steps the model starts overfitting, as described above. Therefore, 500 steps would be your sweet spot, so you would use the `checkpoint-500` model repo in your output dir.\n",
    "\n",
    "You can interrupt the process via Kernel -> Interrupt Kernel in the top nav bar once you realize you didn't need to train anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "c_L1131GyRgo"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yxSbpKQSLY6B"
   },
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "jq0nX33BmfaC",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/FLARE-Challenge/Llama3-models/wandb/run-20240516_100136-oxat2yvg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jiayunliu2000/Flares-finetune/runs/oxat2yvg' target=\"_blank\">llama3-8b-flare-finetune-train-split-JSON-Template1-full-2024-05-16-10-01</a></strong> to <a href='https://wandb.ai/jiayunliu2000/Flares-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jiayunliu2000/Flares-finetune' target=\"_blank\">https://wandb.ai/jiayunliu2000/Flares-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jiayunliu2000/Flares-finetune/runs/oxat2yvg' target=\"_blank\">https://wandb.ai/jiayunliu2000/Flares-finetune/runs/oxat2yvg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2379' max='2379' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2379/2379 3:20:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.063100</td>\n",
       "      <td>0.323499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.279314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.266500</td>\n",
       "      <td>0.268724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.276400</td>\n",
       "      <td>0.261733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.254553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.269300</td>\n",
       "      <td>0.249701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.284400</td>\n",
       "      <td>0.242907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.260400</td>\n",
       "      <td>0.238269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.227314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>0.220104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.212400</td>\n",
       "      <td>0.213827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.207320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>0.202501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.224300</td>\n",
       "      <td>0.195585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.191006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.183359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.174800</td>\n",
       "      <td>0.174248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.168794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.164055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.160351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.157432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.154762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.153523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2379, training_loss=0.2582423016522902, metrics={'train_runtime': 12027.7558, 'train_samples_per_second': 0.395, 'train_steps_per_second': 0.198, 'total_flos': 1.51640721985536e+17, 'train_loss': 0.2582423016522902, 'epoch': 3.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"flare-finetune-train-split-JSON-Template1-full\"\n",
    "base_model_name = \"llama3-8b\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_ratio=0.1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=100,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=100,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=100,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9rRmDCeQiTJ"
   },
   "source": [
    "I cleared the output of the cell above because I stopped the training early, and it produced a long, ugly error message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D57XqcsyRgo"
   },
   "source": [
    "### 6. Drum Roll... Try the Trained Model!\n",
    "\n",
    "It's a good idea to kill the current process so that you don't run out of memory loading the base model again on top of the model we just trained. Go to `Kernel > Restart Kernel` or kill the process via the Terminal (`nvidia smi` > `kill [PID]`). \n",
    "\n",
    "By default, the PEFT library will only save the QLoRA adapters, so we need to first load the base model from the Huggingface Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "fb8230fb86884aa6be318e2d03a88af2"
     ]
    },
    "id": "SKSnF016yRgp",
    "outputId": "bce5209d-90da-4117-c6ac-cda9f3cb3422"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206b20c408e74becaf122087e796ba0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BxOhAiqyRgp"
   },
   "source": [
    "Now load the QLoRA adapter from the appropriate checkpoint directory, i.e. the best performing model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "model_path = \"llama3-8b-flare-finetune-train-split-JSON-Template1-full\"\n",
    "ft_model = PeftModel.from_pretrained(base_model, f\"{model_path}/checkpoint-2300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D57XqcsyRgo"
   },
   "source": [
    "Set stopping criteria to stop the model generating garbage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "class StoppingCriteriaSub(StoppingCriteria):\n",
    "    def __init__(self, stops = [], encounters=1):\n",
    "        super().__init__()\n",
    "        self.stops = [stop.to(\"cuda\") for stop in stops]\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n",
    "        last_token = input_ids[0][-1]\n",
    "        for stop in self.stops:\n",
    "            if tokenizer.decode(stop) == tokenizer.decode(last_token):\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"}\", \"'}}\", \"'}\\n\", \"}}\\n\", \"'}\\n\\n\"]\n",
    "stop_words_ids = [tokenizer(stop_word, return_tensors='pt', add_special_tokens=False)['input_ids'].squeeze() for stop_word in stop_words]\n",
    "stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_words_ids)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lX39ibolyRgp"
   },
   "source": [
    "and run your inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUehsaVNyRgp"
   },
   "source": [
    "Let's try the same `eval_prompt` and thus `model_input` as above, and see if the new finetuned model performs better. I like playing with the repetition penalty (just little tweaks of .01-.05 at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "lMkVNEUvyRgp",
    "outputId": "7d49d409-5dbe-4306-c1a4-9d87e3073397"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"Tu tarea consiste en analizar el texto proporcionado y extraer fragmentos significativos, transcribiéndolos exactamente como aparecen. Asigna a cada fragmento la etiqueta correspondiente basada en la información que representa. Presenta los resultados en formato JSON. Las categorías de etiquetado son:\n",
    "\n",
    "WHO: Sujetos o entidades involucradas.\n",
    "WHAT: Hechos u objetos mencionados.\n",
    "WHEN: Detalles relacionados con el tiempo.\n",
    "WHERE: Lugares mencionados.\n",
    "WHY: Causas o razones.\n",
    "HOW: Maneras o métodos descritos.\n",
    "\n",
    "Abajo es un ejemplo:\n",
    "\n",
    "Input: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que “la mentira tiene las patas muy cortas”. Output: {'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}\n",
    "\n",
    "Ahora, completa la siguiente tarea:\n",
    "\n",
    "Input: Y es que según informa el digital OK Diario, en un artículo que puedes leer en este enlace, el Gobierno de España ha subvencionado con 45.980 euros un estudio sobre el impacto sexista de los piropos. Output:\n",
    "\"\"\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    generated_token = ft_model.generate(**model_input, max_new_tokens=512, stopping_criteria=stopping_criteria)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = eval_tokenizer.decode(generated_token, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tu tarea consiste en analizar el texto proporcionado y extraer fragmentos significativos, transcribiéndolos exactamente como aparecen. Asigna a cada fragmento la etiqueta correspondiente basada en la información que representa. Presenta los resultados en formato JSON. Las categorías de etiquetado son:\n",
      "\n",
      "WHO: Sujetos o entidades involucradas.\n",
      "WHAT: Hechos u objetos mencionados.\n",
      "WHEN: Detalles relacionados con el tiempo.\n",
      "WHERE: Lugares mencionados.\n",
      "WHY: Causas o razones.\n",
      "HOW: Maneras o métodos descritos.\n",
      "\n",
      "Abajo es un ejemplo:\n",
      "\n",
      "Input: Dos días, exactamente han pasado dos días desde que Sánchez compareciera en rueda de prensa en la Moncloa afirmando que a España llegarían, entre abril y septiembre, un total de 87 millones de vacunas para darnos cuenta de que las mentiras de Sánchez hacen bueno ese refrán que dice que “la mentira tiene las patas muy cortas”. Output: {'WHO': ['Sánchez', 'a España', 'de Sánchez'], 'WHERE': ['en rueda de prensa en la Moncloa'], 'WHEN': ['entre abril y septiembre'], 'WHAT': ['un total de 87 millones de vacunas', 'las mentiras', 'ese refrán que dice']}\n",
      "\n",
      "Ahora, completa la siguiente tarea:\n",
      "\n",
      "Input: Y es que según informa el digital OK Diario, en un artículo que puedes leer en este enlace, el Gobierno de España ha subvencionado con 45.980 euros un estudio sobre el impacto sexista de los piropos. Output:\n",
      "Output: {'HOW': ['con 45.980 euros'], 'WHAT': ['un estudio sobre el impacto sexista de los piropos'], 'WHEN': None, 'WHERE': ['en un artículo que puedes leer en este enlace'], 'WHO': ['el digital OK Diario', 'el Gobierno de España'], 'WHY': None}\n"
     ]
    }
   ],
   "source": [
    "print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode only the generated text by slicing the tokens from the length of the input\n",
    "input_length = model_input['input_ids'].size(1)  # Number of tokens in the input\n",
    "generated_text = eval_tokenizer.decode(generated_token[input_length:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: {'HOW': ['con 45.980 euros'], 'WHAT': ['un estudio sobre el impacto sexista de los piropos'], 'WHEN': None, 'WHERE': ['en un artículo que puedes leer en este enlace'], 'WHO': ['el digital OK Diario', 'el Gobierno de España'], 'WHY': None}\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HOW': ['con 45.980 euros'],\n",
       " 'WHAT': ['un estudio sobre el impacto sexista de los piropos'],\n",
       " 'WHEN': None,\n",
       " 'WHERE': ['en un artículo que puedes leer en este enlace'],\n",
       " 'WHO': ['el digital OK Diario', 'el Gobierno de España'],\n",
       " 'WHY': None}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'HOW': ['con 45.980 euros'], 'WHAT': ['un estudio sobre el impacto sexista de los piropos'], 'WHEN': None, 'WHERE': ['en un artículo que puedes leer en este enlace'], 'WHO': ['el digital OK Diario', 'el Gobierno de España'], 'WHY': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCJnpZoayRgq"
   },
   "source": [
    "### 7. FLARE Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 TASK\n",
    "print(tokenized_train_dataset.shape)\n",
    "print(tokenized_val_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = f\"{tokenized_val_dataset[0]['input']} Output:\"\n",
    "print(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    model_input = eval_tokenizer(model_input, return_tensors=\"pt\").to(\"cuda\")\n",
    "    generated_token = ft_model.generate(**model_input, max_new_tokens=512, stopping_criteria=stopping_criteria)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = eval_tokenizer.decode(generated_token, skip_special_tokens=True)\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode only the generated text by slicing the tokens from the length of the input\n",
    "input_length = model_input['input_ids'].size(1)  # Number of tokens in the input\n",
    "generated_text = eval_tokenizer.decode(generated_token[input_length:], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_val_dataset[0]['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the generated text transform to FLARE format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "ft_model.eval()\n",
    "res = []\n",
    "\n",
    "start_time = time.time()  # Start timing before the loop\n",
    "\n",
    "for x in tokenized_val_dataset:\n",
    "    prompt = f\"{x['input']} Output: \"\n",
    "    model_input = eval_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        generated_token = ft_model.generate(**model_input, max_new_tokens=512, stopping_criteria=stopping_criteria)[0]\n",
    "        input_length = model_input['input_ids'].size(1)  # Number of tokens in the input\n",
    "        generated_text = eval_tokenizer.decode(generated_token[input_length:], skip_special_tokens=True)\n",
    "        res.append(generated_text)\n",
    "        \n",
    "end_time = time.time()  # End timing after the loop\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total time spent generating text: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open(f\"{model_path}/results_1900iter.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(res, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"llama3-8b-flare-finetune-train-split-JSON-Template1-lr-2e-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load results\n",
    "with open(f\"{model_path}/results_1900iter.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    res = json.load(file)\n",
    "\n",
    "# Load the data\n",
    "task1_train = pd.read_json('../Flares-dataset/5w1h_subtarea_1_train_train.json', lines=True)\n",
    "task1_test = pd.read_json('../Flares-dataset/5w1h_subtarea_1_train_test.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_index_format(data_dict, original_text):\n",
    "    tags_list = []\n",
    "\n",
    "    for label, fragments in data_dict.items():\n",
    "        if fragments is not None:\n",
    "            for fragment in fragments:\n",
    "                start_index = original_text.find(fragment)\n",
    "                if start_index != -1:\n",
    "                    end_index = start_index + len(fragment)\n",
    "                    tags_list.append({\n",
    "                        'Tag_Start': start_index,\n",
    "                        'Tag_End': end_index,\n",
    "                        '5W1H_Label': label,\n",
    "                        'Tag_Text': fragment\n",
    "                    })\n",
    "    \n",
    "    return tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_test['Text'][250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_train['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Initialize an empty list to store the formatted lists\n",
    "all_formatted_lists = []\n",
    "\n",
    "# Assuming 'convert_to_index_format' is a function and 'task1_test' is a dataset with a column 'Text'\n",
    "for i in range(len(task1_test['Text'])):\n",
    "    try:\n",
    "        # Convert the current item and get the formatted list\n",
    "        formatted_list = convert_to_index_format(ast.literal_eval(res[i]), task1_test['Text'][i])\n",
    "\n",
    "        # Append the formatted list to the collection of all formatted lists\n",
    "        all_formatted_lists.append(formatted_list)\n",
    "        \n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        # If an error occurs, simply skip this item and continue with the next\n",
    "        all_formatted_lists.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting each sublist by 'Tag_Start' key\n",
    "sorted_all_formatted_lists = [sorted(sub_list, key=lambda x: x['Tag_Start']) for sub_list in all_formatted_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=1, width=80, depth=None, compact=False)\n",
    "for i in range(0,2):\n",
    "    print(f\"####Generated tags\")\n",
    "    pp.pprint(sorted_all_formatted_lists[i])\n",
    "    print(f\"####Ground Truh tags\")\n",
    "    pp.pprint(tokenized_val_dataset[i]['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract both 'tags' and 'Id' from each entry and store them in a list of dictionaries\n",
    "ground_truth = [{'Id': entry['Id'], 'Tags': f\"{entry['tags']}\"} for entry in tokenized_val_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame using the IDs and the corresponding formatted tag lists\n",
    "tags_df = pd.DataFrame({\n",
    "    'Id': task1_test['Id'],\n",
    "    'Tags': [str(tags) for tags in sorted_all_formatted_lists]  # Convert each list to a string and enclose it in single quotes\n",
    "})\n",
    "\n",
    "print(tags_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save this DataFrame to a CSV file\n",
    "tags_df.to_csv(f\"{model_path}/tags_data_1900iter.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.DataFrame(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save this DataFrame to a CSV file\n",
    "ground_truth.to_csv(f\"{model_path}/ground_truth.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth['Tags'][135]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST FLARE CHALLENGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python \"../evaluate_subtask_1.py\" --pathDataGold /llama3-8b-flare-finetune-train-split-JSON-Template1-lr-2e-4/ground_truth.csv --pathDataInfered /llama3-8b-flare-finetune-train-split-JSON-Template1-lr-2e-4/tags_data_1900iter.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
