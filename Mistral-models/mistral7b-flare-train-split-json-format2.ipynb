{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VC-9m2yv3m18"
   },
   "source": [
    "## Let's begin!\n",
    "Notebook based on brevdev notebook: https://github.com/brevdev/notebooks/blob/main/mistral-finetune-own-data.ipynb\n",
    "### 0. Preparing data\n",
    "\n",
    "Before you check out a GPU, prepare your dataset for loading and training.\n",
    "\n",
    "To prepare your dataset for loading, all you need are two `.jsonl` files structured something like this:\n",
    "```\n",
    "{\"input\": \"What color is the sky?\", \"output\": \"The sky is blue.\"}\n",
    "{\"input\": \"Where is the best place to get cloud GPUs?\", \"output\": \"Brev.dev\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2CkxsA43m15"
   },
   "source": [
    "### 1. Instantiate GPU & Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FuXIFTFapAMI",
    "outputId": "c8ced1ad-c7b3-44ba-807b-26d7d13906bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# You only need to run this once per machine\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U transformers\n",
    "!pip install -q -U peft\n",
    "!pip install -q -U accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s6f4z8EYmcJ6"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='../data_files/json_format2/5w1h_subtask_1_zero_train_train_json_format2.json', encoding = 'utf-8',split='train')\n",
    "eval_dataset = load_dataset('json', data_files='../data_files/json_format2/5w1h_subtask_1_zero_train_test_json_format2.json', encoding = 'utf-8', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05H5MIfjyRgc"
   },
   "source": [
    "### Accelerator\n",
    "\n",
    "Set up the Accelerator ([description](https://huggingface.co/docs/accelerate/v0.19.0/en/usage_guides/fsdp))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TEzYBadkyRgd"
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9KNTJZkyRgn"
   },
   "source": [
    "\n",
    "Let's use Weights & Biases to track our training metrics. You'll need to apply an API key when prompted. Feel free to skip this if you'd like, and just comment out the `wandb` parameters in the `Trainer` definition below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDqUNyIoyRgo"
   },
   "outputs": [],
   "source": [
    "!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"Flares-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhw8JiOr3m18"
   },
   "source": [
    "### Formatting prompts\n",
    "Then create a `formatting_func` to structure training examples as prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"{example['input']}\\n\\n### Output:\\n{example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sflV0DL2P64_"
   },
   "source": [
    "Here's another common one:\n",
    "\n",
    "```python\n",
    "def formatting_func(example):\n",
    "    text = f\"{example['input']} Output: {example['output']}\"\n",
    "    return text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shz8Xdv-yRgf"
   },
   "source": [
    "### 2. Load Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ-5idQwzvg-"
   },
   "source": [
    "Let's now load Mistral - mistralai/Mistral-7B-v0.1 - using 4-bit quantization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JupyterLab v3.4.6\n",
      "/opt/conda/share/jupyter/labextensions\n",
      "        jupyterlab_pygments v0.2.2 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, jupyterlab_pygments)\n",
      "        jupyter-matplotlib v0.11.2 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n",
      "        @jupyter-widgets/jupyterlab-manager v5.0.3 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, jupyterlab_widgets)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!jupyter labextension list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "45524c98039a46d5b7745ad7cb638d2f"
     ]
    },
    "id": "E0Nl5mWL0k2T",
    "outputId": "47b6b01d-e9f2-4b70-919c-17ae64993843"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7985db4766452fbe46810369f4c9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjNdXolqyRgf"
   },
   "source": [
    "### 3. Tokenization\n",
    "\n",
    "Set up the tokenizer. Add padding on the left as it [makes training use less memory](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa).\n",
    "\n",
    "\n",
    "For `model_max_length`, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "haSUDD9HyRgf",
    "outputId": "22ee95db-2974-4ab0-e0c7-444d04d3e838"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHnKLcq4yRgg"
   },
   "source": [
    "Reformat the prompt and tokenize each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "S3iLAwLh3m19"
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6ewk27p3m19"
   },
   "source": [
    "Let's get a distribution of our dataset lengths, so we can determine the appropriate `max_length` for our input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BA8M9yfC3m19",
    "outputId": "99c6d302-9bb6-47b1-cae9-a1cd870b4770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBk4Qp_vyRgh"
   },
   "source": [
    "From here, you can choose where you'd like to set the `max_length` to be. You can truncate and pad training examples to fit them to your chosen size. Be aware that choosing a larger `max_length` has its compute tradeoffs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMlw8h743m19"
   },
   "source": [
    "Now let's tokenize again with padding and truncation, and set up the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning is](https://neptune.ai/blog/self-supervised-learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "acINaViR3m19"
   },
   "outputs": [],
   "source": [
    "max_length = 700 # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "518d4f0b89bf4d57bf00d4c6d6e59eb5"
     ]
    },
    "id": "lTk-aTog3m19",
    "outputId": "4fb637b4-77a2-47c6-de7b-4fb620663dd7"
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQL796OayRgh"
   },
   "source": [
    "Check that `input_ids` is padded on the left with the `eos_token` (2) and there is an `eos_token` 2 added to the end, and the prompt starts with a `bos_token` (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OKHhvxK83m19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 774, 3133, 3112, 28747, 13, 28738, 28718, 261, 7458, 1037, 2880, 12874, 639, 2245, 28709, 430, 2006, 28717, 296, 1452, 2646, 2562, 921, 283, 337, 4210, 263, 13693, 385, 3753, 9290, 385, 28725, 28705, 13, 28714, 14734, 390, 603, 283, 264, 14150, 13693, 28709, 1849, 911, 2741, 1632, 955, 2977, 28708, 543, 10588, 883, 2166, 340, 543, 5227, 2895, 955, 679, 6863, 28723, 28705, 13, 26102, 1204, 3482, 340, 3173, 1201, 2169, 3482, 481, 1221, 1827, 9292, 28723, 13, 13, 28743, 21800, 12697, 340, 13542, 2741, 299, 1452, 13, 28743, 1540, 13693, 28709, 4210, 28827, 2432, 340, 1105, 23087, 921, 8143, 481, 1849, 340, 2635, 19846, 17459, 20577, 12697, 28747, 13, 13, 20536, 962, 325, 2190, 28797, 1329, 1091, 28877, 4575, 1515, 400, 25786, 28725, 24339, 385, 28725, 289, 13023, 22253, 2442, 28709, 379, 961, 532, 290, 831, 296, 1452, 481, 639, 2245, 28709, 28723, 13, 13, 28780, 4104, 325, 28824, 1724, 2864, 1329, 15220, 20750, 264, 1515, 519, 8358, 385, 289, 936, 11520, 325, 9701, 293, 28725, 6443, 8227, 28725, 4345, 2974, 955, 934, 2892, 28705, 13, 262, 3871, 1485, 28712, 3482, 289, 290, 831, 296, 3482, 481, 639, 2245, 28709, 28723, 13, 13, 20536, 1020, 325, 28743, 28718, 12849, 28709, 1329, 26494, 28706, 1276, 455, 274, 955, 3343, 921, 276, 2470, 385, 289, 3216, 385, 340, 17925, 290, 831, 296, 3482, 481, 639, 2245, 28709, 28723, 13, 13, 28780, 11724, 325, 28757, 28825, 18773, 1329, 9553, 13360, 1515, 9506, 4585, 28725, 7581, 323, 2806, 2970, 21315, 28722, 8368, 289, 3247, 24598, 290, 831, 296, 5959, 481, 639, 2245, 28709, 28723, 13, 13, 20536, 28802, 325, 28753, 271, 25648, 1329, 15220, 20750, 2635, 3599, 293, 28725, 10717, 2402, 289, 8972, 8227, 439, 1256, 5959, 481, 639, 2245, 28709, 28723, 13, 13, 24001, 325, 28743, 28825, 5326, 1329, 27984, 2635, 676, 11234, 28725, 21065, 350, 385, 289, 6803, 321, 19883, 955, 639, 2245, 28709, 1276, 7112, 7469, 21977, 5326, 28705, 13, 331, 16403, 276, 289, 519, 1354, 269, 2635, 6841, 293, 28723, 13, 13, 27332, 11232, 28747, 13, 28835, 19281, 15807, 19538, 9879, 361, 934, 293, 6552, 293, 28725, 281, 1452, 955, 10404, 322, 2737, 934, 14481, 481, 521, 19131, 15807, 17686, 28725, 679, 17914, 4722, 337, 23017, 2567, 6649, 930, 16475, 2646, 543, 679, 831, 1762, 340, 1515, 14986, 11829, 12893, 1150, 274, 289, 277, 615, 293, 955, 11176, 2169, 2567, 639, 18654, 9350, 5233, 4533, 28825, 639, 3197, 24307, 340, 4902, 554, 28723, 13, 13, 27332, 15985, 28747, 13, 18437, 24001, 1869, 3635, 28725, 464, 20536, 962, 1869, 3635, 28725, 464, 20536, 1020, 1869, 3635, 28725, 464, 28780, 11724, 1869, 3635, 28725, 464, 28780, 4104, 1869, 5936, 301, 3197, 24307, 340, 4902, 554, 5807, 464, 20536, 28802, 1869, 3635, 28752, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[2]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 21:58:51.170291: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><s> ### Instruction:\n",
      "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
      "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
      "Los resultados deben ser presentados en formato JSON.\n",
      "\n",
      "Categorías de Etiquetado\n",
      "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
      "\n",
      "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
      "\n",
      "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
      "involucrados o mencionados en el texto.\n",
      "\n",
      "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
      "\n",
      "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
      "\n",
      "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
      "\n",
      "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
      "se realizan o suceden las cosas.\n",
      "\n",
      "### Input:\n",
      "“Es muy importante seguir estas normas, dado que nosotros estamos en un momento muy especial, conteniendo y trabajando fuertemente para la contención de los diferentes linajes o cepas que está presentando el mundo”, concluyó el Ministro de Salud.\n",
      "\n",
      "### Output:\n",
      "{'HOW': None, 'WHAT': None, 'WHEN': None, 'WHERE': None, 'WHO': ['el Ministro de Salud'], 'WHY': None}</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_train_dataset[2]['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6LRa2Zm3m19"
   },
   "source": [
    "Now all the samples should be the same length, `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "I55Yo3yy3m19",
    "outputId": "c87e344d-e0f3-4542-afcc-4e2025926d64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAAIhCAYAAAC48qAWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSg0lEQVR4nO3deVgW9f7/8dctOwi3AgLeiUuGK+6a63HJfU3tpGWhlpYdTSXX/LZZpyQttcWTWscjpqbVSUzLSFzL1HKJSo+pmbsgLQiiBgrz+6Mfc3ULKCAjIM/Hdd3X1XzmPTPvuRnJlzP357YZhmEIAAAAAFCkyhV3AwAAAABwKyJsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBKFOio6Nls9nMl6enp0JCQtSpUydFRUUpKSkpxzbTp0+XzWYr0HEuXryo6dOna8uWLQXaLrdjVa9eXX369CnQfq7nvffe02uvvZbrOpvNpunTpxfp8Yraxo0b1bx5c/n4+Mhms2n16tW51h07dkw2m02vvvrqzW2wAGbMmJFr/9nX6u7du29+U7l4+umnVbVqVbm6uqpChQp51hXmz4uVzpw5o+nTpys+Pr7A22ZfP9HR0detLWnnDaBkIGwBKJMWL16sHTt2KC4uTv/617/UuHFjzZw5U3Xr1tWGDRucakeOHKkdO3YUaP8XL17U888/X+CwVZhjFca1wtaOHTs0cuRIy3soLMMwNGjQILm5uWnNmjXasWOHOnToUNxtFVpeYask+fjjj/XSSy9p6NCh2rp1a44/I391s67h/Dpz5oyef/75QoWtypUra8eOHerdu3fRNwagTHAt7gYAoDiEh4erefPm5vI999yjJ554Qu3atdPAgQN1+PBhBQcHS5KqVKmiKlWqWNrPxYsX5e3tfVOOdT2tWrUq1uNfz5kzZ/T7779rwIAB6ty5c3G3Uybs27dPkjRu3DgFBQVds7YkXMNFxcPDo8T/eQBQsnFnCwD+v6pVq2r27Nk6f/68Fi5caI7n9njQpk2b1LFjRwUEBMjLy0tVq1bVPffco4sXL+rYsWOqVKmSJOn55583H1kcPny40/727t2rv//976pYsaJq1qyZ57GyxcTEqGHDhvL09NTtt9+uN954w2l99mNnx44dcxrfsmWLbDabeZetY8eO+vTTT3X8+HGnRyqz5fYY4b59+3T33XerYsWK8vT0VOPGjbVkyZJcj7NixQo99dRTcjgc8vPzU5cuXXTw4MG83/i/2LZtmzp37ixfX195e3urTZs2+vTTT83106dPN/8iP3XqVNlsNlWvXj1f+76W1NRUTZo0STVq1JC7u7tuu+02RUZG6sKFC051NptNjz/+uJYuXaq6devK29tbjRo10ieffJJjnx9//LEaNmwoDw8P3X777Xr99ddz/HxtNpsuXLigJUuWmD+Hjh07Ou3n/Pnz+sc//qHAwEAFBARo4MCBOnPmjFPNta7Ha8nKytKsWbNUp04deXh4KCgoSEOHDtWpU6fMmurVq+vpp5+WJAUHB1/3MdNrPQobGxurpk2bysvLS3Xq1NF//vMfp7rsazguLk4PPfSQ/P395ePjo759++rnn3/Osc/sP1N/1bFjR/M93LJli1q0aCFJeuihh8z3OL+Pyeb1GOGnn36qxo0by8PDQzVq1MjzMdUPP/xQLVu2lN1ul7e3t26//XY9/PDD+To2gFsDd7YA4C969eolFxcXffHFF3nWHDt2TL1799bf/vY3/ec//1GFChV0+vRpxcbGKiMjQ5UrV1ZsbKx69OihESNGmI/kZQewbAMHDtR9992nxx57LMdf6q8WHx+vyMhITZ8+XSEhIVq+fLnGjx+vjIwMTZo0qUDn+NZbb+nRRx/VkSNHFBMTc936gwcPqk2bNgoKCtIbb7yhgIAALVu2TMOHD9fZs2c1ZcoUp/r/+7//U9u2bfXvf/9bqampmjp1qvr27asDBw7IxcUlz+Ns3bpVXbt2VcOGDbVo0SJ5eHjorbfeUt++fbVixQoNHjxYI0eOVKNGjTRw4ECNHTtWQ4YMkYeHR4HO/2oXL15Uhw4ddOrUKf3f//2fGjZsqP379+vZZ5/VDz/8oA0bNjiFh08//VS7du3SCy+8oPLly2vWrFkaMGCADh48qNtvv12SFBsbq4EDB6p9+/Z6//33deXKFb366qs6e/as07F37Nihu+66S506ddIzzzwjSfLz83OqGTlypHr37q333ntPJ0+e1OTJk/Xggw9q06ZNkq5/PXp7e+d57v/4xz/09ttv6/HHH1efPn107NgxPfPMM9qyZYv27t2rwMBAxcTE6F//+pcWLVqk2NhY2e32Qt25+u677zRx4kQ9+eSTCg4O1r///W+NGDFCd9xxh9q3b+9UO2LECHXt2tU856efflodO3bU999/f83Pi12tadOmWrx4sR566CE9/fTT5uOAN3LnbePGjbr77rvVunVrrVy5UpmZmZo1a1auP9vBgwdr8ODBmj59ujw9PXX8+HHz5wagjDAAoAxZvHixIcnYtWtXnjXBwcFG3bp1zeXnnnvO+Ouvy//+97+GJCM+Pj7Pffzyyy+GJOO5557LsS57f88++2ye6/6qWrVqhs1my3G8rl27Gn5+fsaFCxeczu3o0aNOdZs3bzYkGZs3bzbHevfubVSrVi3X3q/u+7777jM8PDyMEydOONX17NnT8Pb2Ns6dO+d0nF69ejnVffDBB4YkY8eOHbkeL1urVq2MoKAg4/z58+bYlStXjPDwcKNKlSpGVlaWYRiGcfToUUOS8corr1xzf/mtjYqKMsqVK5fjmsj+Oa9bt84ck2QEBwcbqamp5lhiYqJRrlw5Iyoqyhxr0aKFERoaaqSnp5tj58+fNwICAnL8fH18fIxhw4bl6Cv75zl69Gin8VmzZhmSjISEBKc+r3U95ubAgQO57v/rr782JBn/93//Z45lX5e//PLLdfeb1zXs6elpHD9+3By7dOmS4e/vb4waNcocyz7nAQMGOG3/1VdfGZKMF1980Wmfub1vHTp0MDp06GAu79q1y5BkLF68+Lq9Xy37+vnrti1btjQcDodx6dIlcyw1NdXw9/d3Ou9XX33VkGT++QBQNvEYIQBcxTCMa65v3Lix3N3d9eijj2rJkiU5Hm/Kr3vuuSfftfXr11ejRo2cxoYMGaLU1FTt3bu3UMfPr02bNqlz584KDQ11Gh8+fLguXryYYzKEfv36OS03bNhQknT8+PE8j3HhwgV9/fXX+vvf/67y5cub4y4uLoqIiNCpU6fy/ShiQX3yyScKDw9X48aNdeXKFfPVvXt3p8cvs3Xq1Em+vr7mcnBwsIKCgszzu3Dhgnbv3q3+/fvL3d3drCtfvrz69u1b4P6u934W9nrcvHmzJOV4FO/OO+9U3bp1tXHjxgL3ei2NGzdW1apVzWVPT0/VqlUr1+vigQcecFpu06aNqlWrZvZcXC5cuKBdu3Zp4MCB8vT0NMd9fX1z/GyzH18cNGiQPvjgA50+ffqm9gqgZCBsAcBfXLhwQb/99pscDkeeNTVr1tSGDRsUFBSkMWPGqGbNmqpZs6Zef/31Ah2rcuXK+a4NCQnJc+y3334r0HEL6rfffsu11+z36OrjBwQEOC1nP+Z36dKlPI+RnJwswzAKdJyicvbsWX3//fdyc3Nzevn6+sowDP36669O9Vefn/TnOWafX/a5ZE+w8le5jV3P9d7Pwl6P2e9nXu95Ub/f13vf/iqv693qa/16kpOTlZWVdc0/j9nat2+v1atX68qVKxo6dKiqVKmi8PBwrVix4ma1C6AE4DNbAPAXn376qTIzM3NMUnC1v/3tb/rb3/6mzMxM7d69W2+++aYiIyMVHBys++67L1/HKsh38iQmJuY5lv2X2Ox/aU9PT3equzosFFRAQIASEhJyjGdP0hAYGHhD+5ekihUrqly5cpYfJzeBgYHy8vLKMVnDX9cXRMWKFWWz2XJ8hkfK/edYFApzPWZfNwkJCTk+w3TmzBnL3u/8yOt6v+OOO8xlT0/PHNe69Of1blXv2T/ba/15/Ku7775bd999t9LT07Vz505FRUVpyJAhql69ulq3bm1JjwBKFu5sAcD/d+LECU2aNEl2u12jRo3K1zYuLi5q2bKl/vWvf0mS+Uhffu7mFMT+/fv13XffOY2999578vX1VdOmTSXJnJXv+++/d6pbs2ZNjv3ldUchN507d9amTZtyzID37rvvytvbu0imxvbx8VHLli21atUqp76ysrK0bNkyValSRbVq1brh4+SmT58+OnLkiAICAtS8efMcr4LOdujj46PmzZtr9erVysjIMMfT0tJynbWwID+L68nreszNXXfdJUlatmyZ0/iuXbt04MCBYp1Wf/ny5U7L27dv1/Hjx53+EaR69eo5rvVDhw7leNy0KP8s+vj46M4779SqVav0xx9/mOPnz5/X2rVr89zOw8NDHTp00MyZMyVJ33777Q33AqB04M4WgDJp37595mdzkpKS9OWXX2rx4sVycXFRTExMjpkD/2rBggXatGmTevfurapVq+qPP/4w74p06dJF0p+f4ahWrZo+/vhjde7cWf7+/goMDCz0NOUOh0P9+vXT9OnTVblyZS1btkxxcXGaOXOmOdtcixYtVLt2bU2aNElXrlxRxYoVFRMTo23btuXYX4MGDbRq1SrNnz9fzZo1U7ly5Zy+d+yvnnvuOX3yySfq1KmTnn32Wfn7+2v58uX69NNPNWvWLNnt9kKd09WioqLUtWtXderUSZMmTZK7u7veeust7du3TytWrCjQncCr/fDDD/rvf/+bY7xFixaKjIzURx99pPbt2+uJJ55Qw4YNlZWVpRMnTmj9+vWaOHGiWrZsWaDjvfDCC+rdu7e6d++u8ePHKzMzU6+88orKly+v33//3am2QYMG2rJli9auXavKlSvL19dXtWvXzvex8nM95qZ27dp69NFH9eabb6pcuXLq2bOnORthaGionnjiiQKdc1HavXu3Ro4cqXvvvVcnT57UU089pdtuu02jR482ayIiIvTggw9q9OjRuueee3T8+HHNmjUrx5/dmjVrysvLS8uXL1fdunVVvnx5ORyOaz4qfC3//Oc/1aNHD3Xt2lUTJ05UZmamZs6cKR8fH6ef7bPPPqtTp06pc+fOqlKlis6dO6fXX39dbm5upfpLuAEUUPHOzwEAN1f2bGfZL3d3dyMoKMjo0KGDMWPGDCMpKSnHNlfPrrZjxw5jwIABRrVq1QwPDw8jICDA6NChg7FmzRqn7TZs2GA0adLE8PDwMCSZM6dda2a3vGZy6927t/Hf//7XqF+/vuHu7m5Ur17dmDNnTo7tDx06ZHTr1s3w8/MzKlWqZIwdO9b49NNPc8xG+Pvvvxt///vfjQoVKhg2m83pmMplFsUffvjB6Nu3r2G32w13d3ejUaNGOWZ3y56N8MMPP3Qaz21Gt7x8+eWXxl133WX4+PgYXl5eRqtWrYy1a9fmur+CzEaY1yu7p7S0NOPpp582ateubbi7uxt2u91o0KCB8cQTTxiJiYlO782YMWNyHCe3mfFiYmKMBg0aGO7u7kbVqlWNl19+2Rg3bpxRsWJFp7r4+Hijbdu2hre3tyHJnEkvr5kzr55dMr/XY24yMzONmTNnGrVq1TLc3NyMwMBA48EHHzROnjzpVFcUsxH27t07R+3VMwdmn/P69euNiIgIo0KFCoaXl5fRq1cv4/Dhw07bZmVlGbNmzTJuv/12w9PT02jevLmxadOmHPs0DMNYsWKFUadOHcPNzS3PWUJzk9e1u2bNGqNhw4ZOP9urz/uTTz4xevbsadx2223m75levXoZX375Zb6ODeDWYDOM60y7BQAAbtjly5fVuHFj3XbbbVq/fn1xt1MiRUdH66GHHtKuXbvyvNMKAKUJjxECAGCB7C/mrVy5shITE7VgwQIdOHCgwLNWAgBKL8IWAAAWOH/+vCZNmqRffvlFbm5uatq0qdatW3fNz1Hh5jAMQ5mZmdescXFxuaHPCQKAJPEYIQAAKFO2bNmiTp06XbNm8eLFOb7wGQAKirAFAADKlPPnz+eYIv5qNWrUyPWLmAGgIAhbAAAAAGABvtQYAAAAACzABBn5lJWVpTNnzsjX15cPzAIAAABlmGEYOn/+vBwOh8qVy/v+FWErn86cOaPQ0NDibgMAAABACXHy5ElVqVIlz/WErXzy9fWV9Ocb6ufnV8zdAAAAACguqampCg0NNTNCXghb+ZT96KCfnx9hCwAAAMB1P17EBBkAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFijWsPXFF1+ob9++cjgcstlsWr16dY6aAwcOqF+/frLb7fL19VWrVq104sQJc316errGjh2rwMBA+fj4qF+/fjp16pTTPpKTkxURESG73S673a6IiAidO3fO4rMDAAAAUJYVa9i6cOGCGjVqpHnz5uW6/siRI2rXrp3q1KmjLVu26LvvvtMzzzwjT09PsyYyMlIxMTFauXKltm3bprS0NPXp00eZmZlmzZAhQxQfH6/Y2FjFxsYqPj5eERERlp8fAAAAgLLLZhiGUdxNSJLNZlNMTIz69+9vjt13331yc3PT0qVLc90mJSVFlSpV0tKlSzV48GBJ0pkzZxQaGqp169ape/fuOnDggOrVq6edO3eqZcuWkqSdO3eqdevW+vHHH1W7du1c952enq709HRzOTU1VaGhoUpJSZGfn18RnTUAAACA0iY1NVV2u/262aDEfmYrKytLn376qWrVqqXu3bsrKChILVu2dHrUcM+ePbp8+bK6detmjjkcDoWHh2v79u2SpB07dshut5tBS5JatWolu91u1uQmKirKfOzQbrcrNDS06E8SAAAAwC2rxIatpKQkpaWl6eWXX1aPHj20fv16DRgwQAMHDtTWrVslSYmJiXJ3d1fFihWdtg0ODlZiYqJZExQUlGP/QUFBZk1upk2bppSUFPN18uTJIjw7AAAAALc61+JuIC9ZWVmSpLvvvltPPPGEJKlx48bavn27FixYoA4dOuS5rWEYstls5vJf/zuvmqt5eHjIw8OjsO0DAAAAKONK7J2twMBAubq6ql69ek7jdevWNWcjDAkJUUZGhpKTk51qkpKSFBwcbNacPXs2x/5/+eUXswYAAAAAilqJDVvu7u5q0aKFDh486DR+6NAhVatWTZLUrFkzubm5KS4uzlyfkJCgffv2qU2bNpKk1q1bKyUlRd98841Z8/XXXyslJcWsAQAAAICiVqyPEaalpemnn34yl48ePar4+Hj5+/uratWqmjx5sgYPHqz27durU6dOio2N1dq1a7VlyxZJkt1u14gRIzRx4kQFBATI399fkyZNUoMGDdSlSxdJf94J69Gjhx555BEtXLhQkvToo4+qT58+ec5ECABAXvr2Le4OnK1dW9wdAADyUqxha/fu3erUqZO5PGHCBEnSsGHDFB0drQEDBmjBggWKiorSuHHjVLt2bX300Udq166duc3cuXPl6uqqQYMG6dKlS+rcubOio6Pl4uJi1ixfvlzjxo0zZy3s169fnt/tBQAAAABFocR8z1ZJl9+59AEAtzbubAEASv33bAEAAABAaUbYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsECxhq0vvvhCffv2lcPhkM1m0+rVq/OsHTVqlGw2m1577TWn8fT0dI0dO1aBgYHy8fFRv379dOrUKaea5ORkRUREyG63y263KyIiQufOnSv6EwIAAACA/69Yw9aFCxfUqFEjzZs375p1q1ev1tdffy2Hw5FjXWRkpGJiYrRy5Upt27ZNaWlp6tOnjzIzM82aIUOGKD4+XrGxsYqNjVV8fLwiIiKK/HwAAAAAIJtrcR68Z8+e6tmz5zVrTp8+rccff1yff/65evfu7bQuJSVFixYt0tKlS9WlSxdJ0rJlyxQaGqoNGzaoe/fuOnDggGJjY7Vz5061bNlSkvTOO++odevWOnjwoGrXrm3NyQEAAAAo00r0Z7aysrIUERGhyZMnq379+jnW79mzR5cvX1a3bt3MMYfDofDwcG3fvl2StGPHDtntdjNoSVKrVq1kt9vNmtykp6crNTXV6QUAAAAA+VWiw9bMmTPl6uqqcePG5bo+MTFR7u7uqlixotN4cHCwEhMTzZqgoKAc2wYFBZk1uYmKijI/42W32xUaGnoDZwIAAACgrCmxYWvPnj16/fXXFR0dLZvNVqBtDcNw2ia37a+uudq0adOUkpJivk6ePFmgHgAAAACUbSU2bH355ZdKSkpS1apV5erqKldXVx0/flwTJ05U9erVJUkhISHKyMhQcnKy07ZJSUkKDg42a86ePZtj/7/88otZkxsPDw/5+fk5vQAAAAAgv0ps2IqIiND333+v+Ph48+VwODR58mR9/vnnkqRmzZrJzc1NcXFx5nYJCQnat2+f2rRpI0lq3bq1UlJS9M0335g1X3/9tVJSUswaAAAAAChqxTobYVpamn766Sdz+ejRo4qPj5e/v7+qVq2qgIAAp3o3NzeFhISYMwja7XaNGDFCEydOVEBAgPz9/TVp0iQ1aNDAnJ2wbt266tGjhx555BEtXLhQkvToo4+qT58+zEQIAAAAwDLFGrZ2796tTp06mcsTJkyQJA0bNkzR0dH52sfcuXPl6uqqQYMG6dKlS+rcubOio6Pl4uJi1ixfvlzjxo0zZy3s16/fdb/bCwAAAABuhM0wDKO4mygNUlNTZbfblZKSwue3AKAM69u3uDtwtnZtcXcAAGVPfrNBif3MFgAAAACUZoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMACxRq2vvjiC/Xt21cOh0M2m02rV682112+fFlTp05VgwYN5OPjI4fDoaFDh+rMmTNO+0hPT9fYsWMVGBgoHx8f9evXT6dOnXKqSU5OVkREhOx2u+x2uyIiInTu3LmbcIYAAAAAyqpiDVsXLlxQo0aNNG/evBzrLl68qL179+qZZ57R3r17tWrVKh06dEj9+vVzqouMjFRMTIxWrlypbdu2KS0tTX369FFmZqZZM2TIEMXHxys2NlaxsbGKj49XRESE5ecHAAAAoOyyGYZhFHcTkmSz2RQTE6P+/fvnWbNr1y7deeedOn78uKpWraqUlBRVqlRJS5cu1eDBgyVJZ86cUWhoqNatW6fu3bvrwIEDqlevnnbu3KmWLVtKknbu3KnWrVvrxx9/VO3atXM9Vnp6utLT083l1NRUhYaGKiUlRX5+fkV34gCAUqVv3+LuwNnatcXdAQCUPampqbLb7dfNBqXqM1spKSmy2WyqUKGCJGnPnj26fPmyunXrZtY4HA6Fh4dr+/btkqQdO3bIbrebQUuSWrVqJbvdbtbkJioqynzs0G63KzQ01JqTAgAAAHBLKjVh648//tCTTz6pIUOGmOkxMTFR7u7uqlixolNtcHCwEhMTzZqgoKAc+wsKCjJrcjNt2jSlpKSYr5MnTxbh2QAAAAC41bkWdwP5cfnyZd13333KysrSW2+9dd16wzBks9nM5b/+d141V/Pw8JCHh0fhGgYAAABQ5pX4O1uXL1/WoEGDdPToUcXFxTk9ExkSEqKMjAwlJyc7bZOUlKTg4GCz5uzZszn2+8svv5g1AAAAAFDUSnTYyg5ahw8f1oYNGxQQEOC0vlmzZnJzc1NcXJw5lpCQoH379qlNmzaSpNatWyslJUXffPONWfP1118rJSXFrAEAAACAolasjxGmpaXpp59+MpePHj2q+Ph4+fv7y+Fw6O9//7v27t2rTz75RJmZmeZnrPz9/eXu7i673a4RI0Zo4sSJCggIkL+/vyZNmqQGDRqoS5cukqS6deuqR48eeuSRR7Rw4UJJ0qOPPqo+ffrkORMhAAAAANyoYg1bu3fvVqdOnczlCRMmSJKGDRum6dOna82aNZKkxo0bO223efNmdezYUZI0d+5cubq6atCgQbp06ZI6d+6s6Ohoubi4mPXLly/XuHHjzFkL+/Xrl+t3ewEAAABAUSkx37NV0uV3Ln0AwK2N79kCANyS37MFAAAAAKUFYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMACxRq2vvjiC/Xt21cOh0M2m02rV692Wm8YhqZPny6HwyEvLy917NhR+/fvd6pJT0/X2LFjFRgYKB8fH/Xr10+nTp1yqklOTlZERITsdrvsdrsiIiJ07tw5i88OAAAAQFlWrGHrwoULatSokebNm5fr+lmzZmnOnDmaN2+edu3apZCQEHXt2lXnz583ayIjIxUTE6OVK1dq27ZtSktLU58+fZSZmWnWDBkyRPHx8YqNjVVsbKzi4+MVERFh+fkBAAAAKLtshmEYxd2EJNlsNsXExKh///6S/ryr5XA4FBkZqalTp0r68y5WcHCwZs6cqVGjRiklJUWVKlXS0qVLNXjwYEnSmTNnFBoaqnXr1ql79+46cOCA6tWrp507d6ply5aSpJ07d6p169b68ccfVbt27Xz1l5qaKrvdrpSUFPn5+RX9GwAAKBX69i3uDpytXVvcHQBA2ZPfbFBiP7N19OhRJSYmqlu3buaYh4eHOnTooO3bt0uS9uzZo8uXLzvVOBwOhYeHmzU7duyQ3W43g5YktWrVSna73azJTXp6ulJTU51eAAAAAJBfJTZsJSYmSpKCg4OdxoODg811iYmJcnd3V8WKFa9ZExQUlGP/QUFBZk1uoqKizM942e12hYaG3tD5AAAAAChbSmzYymaz2ZyWDcPIMXa1q2tyq7/efqZNm6aUlBTzdfLkyQJ2DgAAAKAsK7FhKyQkRJJy3H1KSkoy73aFhIQoIyNDycnJ16w5e/Zsjv3/8ssvOe6a/ZWHh4f8/PycXgAAAACQXyU2bNWoUUMhISGKi4szxzIyMrR161a1adNGktSsWTO5ubk51SQkJGjfvn1mTevWrZWSkqJvvvnGrPn666+VkpJi1gAAAABAUXMtzoOnpaXpp59+MpePHj2q+Ph4+fv7q2rVqoqMjNSMGTMUFhamsLAwzZgxQ97e3hoyZIgkyW63a8SIEZo4caICAgLk7++vSZMmqUGDBurSpYskqW7duurRo4ceeeQRLVy4UJL06KOPqk+fPvmeiRAAAAAACqpYw9bu3bvVqVMnc3nChAmSpGHDhik6OlpTpkzRpUuXNHr0aCUnJ6tly5Zav369fH19zW3mzp0rV1dXDRo0SJcuXVLnzp0VHR0tFxcXs2b58uUaN26cOWthv3798vxuLwAAAAAoCiXme7ZKOr5nCwAg8T1bAIBb4Hu2AAAAAKA0I2wBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYIFCha2jR48WdR8AAAAAcEspVNi644471KlTJy1btkx//PFHUfcEAAAAAKVeocLWd999pyZNmmjixIkKCQnRqFGj9M033xR1bwAAAABQahUqbIWHh2vOnDk6ffq0Fi9erMTERLVr107169fXnDlz9MsvvxR1nwAAAABQqtzQBBmurq4aMGCAPvjgA82cOVNHjhzRpEmTVKVKFQ0dOlQJCQlF1ScAAAAAlCo3FLZ2796t0aNHq3LlypozZ44mTZqkI0eOaNOmTTp9+rTuvvvuouoTAAAAAEoV18JsNGfOHC1evFgHDx5Ur1699O6776pXr14qV+7P7FajRg0tXLhQderUKdJmAQAAAKC0KFTYmj9/vh5++GE99NBDCgkJybWmatWqWrRo0Q01BwAAAAClVaHC1uHDh69b4+7urmHDhhVm9wAAAABQ6hXqM1uLFy/Whx9+mGP8ww8/1JIlS264KQAAAAAo7QoVtl5++WUFBgbmGA8KCtKMGTNuuCkAAAAAKO0KFbaOHz+uGjVq5BivVq2aTpw4ccNNAQAAAEBpV6iwFRQUpO+//z7H+HfffaeAgIAbbgoAAAAASrtCha377rtP48aN0+bNm5WZmanMzExt2rRJ48eP13333VfUPQIAAABAqVOo2QhffPFFHT9+XJ07d5ar65+7yMrK0tChQ/nMFgAAAACokGHL3d1d77//vv75z3/qu+++k5eXlxo0aKBq1aoVdX8AAAAAUCoVKmxlq1WrlmrVqlVUvQAAAADALaNQYSszM1PR0dHauHGjkpKSlJWV5bR+06ZNRdIcAAAAAJRWhQpb48ePV3R0tHr37q3w8HDZbLai7gsAAAAASrVCha2VK1fqgw8+UK9evYq6HwAAAAC4JRRq6nd3d3fdcccdRd0LAAAAANwyChW2Jk6cqNdff12GYRR1PwAAAABwSyjUY4Tbtm3T5s2b9dlnn6l+/fpyc3NzWr9q1aoiaQ4AAAAASqtCha0KFSpowIABRd0LAAAAANwyChW2Fi9eXNR9AAAAAMAtpVCf2ZKkK1euaMOGDVq4cKHOnz8vSTpz5ozS0tKKrDkAAAAAKK0KdWfr+PHj6tGjh06cOKH09HR17dpVvr6+mjVrlv744w8tWLCgqPsEAAAAgFKlUHe2xo8fr+bNmys5OVleXl7m+IABA7Rx48Yiaw4AAAAASqtCz0b41Vdfyd3d3Wm8WrVqOn36dJE0BgAAAAClWaHubGVlZSkzMzPH+KlTp+Tr63vDTQEAAABAaVeosNW1a1e99tpr5rLNZlNaWpqee+459erVq6h6AwAAAIBSq1CPEc6dO1edOnVSvXr19Mcff2jIkCE6fPiwAgMDtWLFiqLuEQAAAABKnUKFLYfDofj4eK1YsUJ79+5VVlaWRowYoQceeMBpwgwAAAAAKKsKFbYkycvLSw8//LAefvjhouwHAAAAAG4JhQpb77777jXXDx06tFDNAAAAAMCtolBha/z48U7Lly9f1sWLF+Xu7i5vb2/CFgAAAIAyr1CzESYnJzu90tLSdPDgQbVr144JMgAAAABAhQxbuQkLC9PLL7+c464XAAAAAJRFRRa2JMnFxUVnzpwpsv1duXJFTz/9tGrUqCEvLy/dfvvteuGFF5SVlWXWGIah6dOny+FwyMvLSx07dtT+/fud9pOenq6xY8cqMDBQPj4+6tevn06dOlVkfQIAAADA1Qr1ma01a9Y4LRuGoYSEBM2bN09t27YtksYkaebMmVqwYIGWLFmi+vXra/fu3XrooYdkt9vNO2izZs3SnDlzFB0drVq1aunFF19U165ddfDgQfn6+kqSIiMjtXbtWq1cuVIBAQGaOHGi+vTpoz179sjFxaXI+gUAAACAbDbDMIyCblSunPMNMZvNpkqVKumuu+7S7NmzVbly5SJprk+fPgoODtaiRYvMsXvuuUfe3t5aunSpDMOQw+FQZGSkpk6dKunPu1jBwcGaOXOmRo0apZSUFFWqVElLly7V4MGDJUlnzpxRaGio1q1bp+7du+d67PT0dKWnp5vLqampCg0NVUpKivz8/Irk/AAApU/fvsXdgbO1a4u7AwAoe1JTU2W326+bDQr1GGFWVpbTKzMzU4mJiXrvvfeKLGhJUrt27bRx40YdOnRIkvTdd99p27Zt6tWrlyTp6NGjSkxMVLdu3cxtPDw81KFDB23fvl2StGfPHl2+fNmpxuFwKDw83KzJTVRUlOx2u/kKDQ0tsvMCAAAAcOsr9Jca3wxTp05VSkqK6tSpIxcXF2VmZuqll17S/fffL0lKTEyUJAUHBzttFxwcrOPHj5s17u7uqlixYo6a7O1zM23aNE2YMMFczr6zBQAAAAD5Uaiw9dcQcj1z5swpzCEkSe+//76WLVum9957T/Xr11d8fLwiIyPlcDg0bNgws85mszltZxhGjrGrXa/Gw8NDHh4ehe4dAAAAQNlWqLD17bffau/evbpy5Ypq164tSTp06JBcXFzUtGlTs+56ged6Jk+erCeffFL33XefJKlBgwY6fvy4oqKiNGzYMIWEhEj68+7VXx9fTEpKMu92hYSEKCMjQ8nJyU53t5KSktSmTZsb6g8AAAAA8lKoz2z17dtXHTp00KlTp7R3717t3btXJ0+eVKdOndSnTx9t3rxZmzdv1qZNm26ouYsXL+aYjMPFxcWc+r1GjRoKCQlRXFycuT4jI0Nbt241g1SzZs3k5ubmVJOQkKB9+/YRtgAAAABYplB3tmbPnq3169c73SmqWLGiXnzxRXXr1k0TJ04skub69u2rl156SVWrVlX9+vX17bffas6cOXr44Ycl/XnnLDIyUjNmzFBYWJjCwsI0Y8YMeXt7a8iQIZIku92uESNGaOLEiQoICJC/v78mTZqkBg0aqEuXLkXSJwAAAABcrVBhKzU1VWfPnlX9+vWdxpOSknT+/PkiaUyS3nzzTT3zzDMaPXq0kpKS5HA4NGrUKD377LNmzZQpU3Tp0iWNHj1aycnJatmypdavX29+x5YkzZ07V66urho0aJAuXbqkzp07Kzo6mu/YAgAAAGCZQn3P1tChQ7V161bNnj1brVq1kiTt3LlTkydPVvv27bVkyZIib7S45XcufQDArY3v2QIA5DcbFOrO1oIFCzRp0iQ9+OCDunz58p87cnXViBEj9MorrxSuYwAAAAC4hRTqzla2Cxcu6MiRIzIMQ3fccYd8fHyKsrcShTtbAACJO1sAgPxng0LNRpgtISFBCQkJqlWrlnx8fHQDuQ0AAAAAbimFClu//fabOnfurFq1aqlXr15KSEiQJI0cObLIZiIEAAAAgNKsUGHriSeekJubm06cOCFvb29zfPDgwYqNjS2y5gAAAACgtCrUBBnr16/X559/ripVqjiNh4WF6fjx40XSGAAAAACUZoW6s3XhwgWnO1rZfv31V3l4eNxwUwAAAABQ2hUqbLVv317vvvuuuWyz2ZSVlaVXXnlFnTp1KrLmAAAAAKC0KtRjhK+88oo6duyo3bt3KyMjQ1OmTNH+/fv1+++/66uvvirqHgEAAACg1CnUna169erp+++/15133qmuXbvqwoULGjhwoL799lvVrFmzqHsEAAAAgFKnwHe2Ll++rG7dumnhwoV6/vnnregJAAAAAEq9At/ZcnNz0759+2Sz2azoBwAAAABuCYV6jHDo0KFatGhRUfcCAAAAALeMQk2QkZGRoX//+9+Ki4tT8+bN5ePj47R+zpw5RdIcAAAAAJRWBQpbP//8s6pXr659+/apadOmkqRDhw451fB4IQAAAAAUMGyFhYUpISFBmzdvliQNHjxYb7zxhoKDgy1pDgAAAABKqwJ9ZsswDKflzz77TBcuXCjShgAAAADgVlCoCTKyXR2+AAAAAAB/KlDYstlsOT6TxWe0AAAAACCnAn1myzAMDR8+XB4eHpKkP/74Q4899liO2QhXrVpVdB0CAAAAQClUoLA1bNgwp+UHH3ywSJsBAAAAgFtFgcLW4sWLreoDAAAAAG4pNzRBBgAAAAAgd4QtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsECJD1unT5/Wgw8+qICAAHl7e6tx48bas2ePud4wDE2fPl0Oh0NeXl7q2LGj9u/f77SP9PR0jR07VoGBgfLx8VG/fv106tSpm30qAAAAAMqQEh22kpOT1bZtW7m5uemzzz7T//73P82ePVsVKlQwa2bNmqU5c+Zo3rx52rVrl0JCQtS1a1edP3/erImMjFRMTIxWrlypbdu2KS0tTX369FFmZmYxnBUAAACAssBmGIZR3E3k5cknn9RXX32lL7/8Mtf1hmHI4XAoMjJSU6dOlfTnXazg4GDNnDlTo0aNUkpKiipVqqSlS5dq8ODBkqQzZ84oNDRU69atU/fu3fPVS2pqqux2u1JSUuTn51c0JwgAKHX69i3uDpytXVvcHQBA2ZPfbFCi72ytWbNGzZs317333qugoCA1adJE77zzjrn+6NGjSkxMVLdu3cwxDw8PdejQQdu3b5ck7dmzR5cvX3aqcTgcCg8PN2tyk56ertTUVKcXAAAAAORXiQ5bP//8s+bPn6+wsDB9/vnneuyxxzRu3Di9++67kqTExERJUnBwsNN2wcHB5rrExES5u7urYsWKedbkJioqSna73XyFhoYW5akBAAAAuMWV6LCVlZWlpk2basaMGWrSpIlGjRqlRx55RPPnz3eqs9lsTsuGYeQYu9r1aqZNm6aUlBTzdfLkycKfCAAAAIAyp0SHrcqVK6tevXpOY3Xr1tWJEyckSSEhIZKU4w5VUlKSebcrJCREGRkZSk5OzrMmNx4eHvLz83N6AQAAAEB+leiw1bZtWx08eNBp7NChQ6pWrZokqUaNGgoJCVFcXJy5PiMjQ1u3blWbNm0kSc2aNZObm5tTTUJCgvbt22fWAAAAAEBRcy3uBq7liSeeUJs2bTRjxgwNGjRI33zzjd5++229/fbbkv58fDAyMlIzZsxQWFiYwsLCNGPGDHl7e2vIkCGSJLvdrhEjRmjixIkKCAiQv7+/Jk2apAYNGqhLly7FeXoAAAAAbmElOmy1aNFCMTExmjZtml544QXVqFFDr732mh544AGzZsqUKbp06ZJGjx6t5ORktWzZUuvXr5evr69ZM3fuXLm6umrQoEG6dOmSOnfurOjoaLm4uBTHaQEAAAAoA0r092yVJHzPFgBA4nu2AAC3yPdsAQAAAEBpRdgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxQqsJWVFSUbDabIiMjzTHDMDR9+nQ5HA55eXmpY8eO2r9/v9N26enpGjt2rAIDA+Xj46N+/frp1KlTN7l7AAAAAGVJqQlbu3bt0ttvv62GDRs6jc+aNUtz5szRvHnztGvXLoWEhKhr1646f/68WRMZGamYmBitXLlS27ZtU1pamvr06aPMzMybfRoAAAAAyohSEbbS0tL0wAMP6J133lHFihXNccMw9Nprr+mpp57SwIEDFR4eriVLlujixYt67733JEkpKSlatGiRZs+erS5duqhJkyZatmyZfvjhB23YsKG4TgkAAADALa5UhK0xY8aod+/e6tKli9P40aNHlZiYqG7dupljHh4e6tChg7Zv3y5J2rNnjy5fvuxU43A4FB4ebtbkJj09XampqU4vAAAAAMgv1+Ju4HpWrlypvXv3ateuXTnWJSYmSpKCg4OdxoODg3X8+HGzxt3d3emOWHZN9va5iYqK0vPPP3+j7QMAAAAoo0r0na2TJ09q/PjxWrZsmTw9PfOss9lsTsuGYeQYu9r1aqZNm6aUlBTzdfLkyYI1DwAAAKBMK9Fha8+ePUpKSlKzZs3k6uoqV1dXbd26VW+88YZcXV3NO1pX36FKSkoy14WEhCgjI0PJycl51uTGw8NDfn5+Ti8AAAAAyK8SHbY6d+6sH374QfHx8earefPmeuCBBxQfH6/bb79dISEhiouLM7fJyMjQ1q1b1aZNG0lSs2bN5Obm5lSTkJCgffv2mTUAAAAAUNRK9Ge2fH19FR4e7jTm4+OjgIAAczwyMlIzZsxQWFiYwsLCNGPGDHl7e2vIkCGSJLvdrhEjRmjixIkKCAiQv7+/Jk2apAYNGuSYcAMAAAAAikqJDlv5MWXKFF26dEmjR49WcnKyWrZsqfXr18vX19esmTt3rlxdXTVo0CBdunRJnTt3VnR0tFxcXIqxcwAAAAC3MpthGEZxN1EapKamym63KyUlhc9vAUAZ1rdvcXfgbO3a4u4AAMqe/GaDEv2ZLQAAAAAorQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFijRYSsqKkotWrSQr6+vgoKC1L9/fx08eNCpxjAMTZ8+XQ6HQ15eXurYsaP279/vVJOenq6xY8cqMDBQPj4+6tevn06dOnUzTwUAAABAGVOiw9bWrVs1ZswY7dy5U3Fxcbpy5Yq6deumCxcumDWzZs3SnDlzNG/ePO3atUshISHq2rWrzp8/b9ZERkYqJiZGK1eu1LZt25SWlqY+ffooMzOzOE4LAAAAQBlgMwzDKO4m8uuXX35RUFCQtm7dqvbt28swDDkcDkVGRmrq1KmS/ryLFRwcrJkzZ2rUqFFKSUlRpUqVtHTpUg0ePFiSdObMGYWGhmrdunXq3r17vo6dmpoqu92ulJQU+fn5WXaOAICSrW/f4u7A2dq1xd0BAJQ9+c0GJfrO1tVSUlIkSf7+/pKko0ePKjExUd26dTNrPDw81KFDB23fvl2StGfPHl2+fNmpxuFwKDw83KzJTXp6ulJTU51eAAAAAJBfpSZsGYahCRMmqF27dgoPD5ckJSYmSpKCg4OdaoODg811iYmJcnd3V8WKFfOsyU1UVJTsdrv5Cg0NLcrTAQAAAHCLKzVh6/HHH9f333+vFStW5Fhns9mclg3DyDF2tevVTJs2TSkpKebr5MmThWscAAAAQJlUKsLW2LFjtWbNGm3evFlVqlQxx0NCQiQpxx2qpKQk825XSEiIMjIylJycnGdNbjw8POTn5+f0AgAAAID8KtFhyzAMPf7441q1apU2bdqkGjVqOK2vUaOGQkJCFBcXZ45lZGRo69atatOmjSSpWbNmcnNzc6pJSEjQvn37zBoAAAAAKGquxd3AtYwZM0bvvfeePv74Y/n6+pp3sOx2u7y8vGSz2RQZGakZM2YoLCxMYWFhmjFjhry9vTVkyBCzdsSIEZo4caICAgLk7++vSZMmqUGDBurSpUtxnh4AAACAW1iJDlvz58+XJHXs2NFpfPHixRo+fLgkacqUKbp06ZJGjx6t5ORktWzZUuvXr5evr69ZP3fuXLm6umrQoEG6dOmSOnfurOjoaLm4uNysUwEAAABQxpSq79kqTnzPFgBA4nu2AAC36PdsAQAAAEBpQdgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxQpsLWW2+9pRo1asjT01PNmjXTl19+WdwtAQAAALhFlZmw9f777ysyMlJPPfWUvv32W/3tb39Tz549deLEieJuDQAAAMAtqMyErTlz5mjEiBEaOXKk6tatq9dee02hoaGaP39+cbcGAAAA4BbkWtwN3AwZGRnas2ePnnzySafxbt26afv27bluk56ervT0dHM5JSVFkpSammpdowCAEu/y5eLuwBn/WwKAmy87ExiGcc26MhG2fv31V2VmZio4ONhpPDg4WImJibluExUVpeeffz7HeGhoqCU9AgBQGHZ7cXcAAGXX+fPnZb/GL+IyEbay2Ww2p2XDMHKMZZs2bZomTJhgLmdlZen3339XQEBAntugeKWmpio0NFQnT56Un59fcbeDUoBrBgXFNYOC4ppBQXHNlA6GYej8+fNyOBzXrCsTYSswMFAuLi457mIlJSXluNuVzcPDQx4eHk5jFSpUsKpFFCE/Pz9+OaFAuGZQUFwzKCiuGRQU10zJd607WtnKxAQZ7u7uatasmeLi4pzG4+Li1KZNm2LqCgAAAMCtrEzc2ZKkCRMmKCIiQs2bN1fr1q319ttv68SJE3rssceKuzUAAAAAt6AyE7YGDx6s3377TS+88IISEhIUHh6udevWqVq1asXdGoqIh4eHnnvuuRyPfwJ54ZpBQXHNoKC4ZlBQXDO3FptxvfkKAQAAAAAFViY+swUAAAAANxthCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtlBinT5/Wgw8+qICAAHl7e6tx48bas2ePuf7s2bMaPny4HA6HvL291aNHDx0+fNhpH0eOHNGAAQNUqVIl+fn5adCgQTp79uwNHxslT3FdL1euXNHTTz+tGjVqyMvLS7fffrteeOEFZWVlWXKeKBrVq1eXzWbL8RozZowkyTAMTZ8+XQ6HQ15eXurYsaP279/vtI/09HSNHTtWgYGB8vHxUb9+/XTq1KnrHvutt95SjRo15OnpqWbNmunLL7+05BxRtIrrmomKilKLFi3k6+uroKAg9e/fXwcPHrTsPFF0ivP3TLaoqCjZbDZFRkYW5anhBhC2UCIkJyerbdu2cnNz02effab//e9/mj17tipUqCDpz19Q/fv3188//6yPP/5Y3377rapVq6YuXbrowoULkqQLFy6oW7dustls2rRpk7766itlZGSob9++1/yL8PWOjZKnOK+XmTNnasGCBZo3b54OHDigWbNm6ZVXXtGbb755M04dhbRr1y4lJCSYr+wvub/33nslSbNmzdKcOXM0b9487dq1SyEhIeratavOnz9v7iMyMlIxMTFauXKltm3bprS0NPXp00eZmZl5Hvf9999XZGSknnrqKX377bf629/+pp49e+rEiRPWnjBuWHFdM1u3btWYMWO0c+dOxcXF6cqVK+rWrZv5uwslV3FdM389/ttvv62GDRtac4IoHAMoAaZOnWq0a9cuz/UHDx40JBn79u0zx65cuWL4+/sb77zzjmEYhvH5558b5cqVM1JSUsya33//3ZBkxMXFFfrYKHmK83rp3bu38fDDDzuNDRw40HjwwQcLezooBuPHjzdq1qxpZGVlGVlZWUZISIjx8ssvm+v/+OMPw263GwsWLDAMwzDOnTtnuLm5GStXrjRrTp8+bZQrV86IjY3N8zh33nmn8dhjjzmN1alTx3jyySeL+IxgtZt1zVwtKSnJkGRs3bq16E4GN8XNvGbOnz9vhIWFGXFxcUaHDh2M8ePHW3JOKDjubKFEWLNmjZo3b657771XQUFBatKkid555x1zfXp6uiTJ09PTHHNxcZG7u7u2bdtm1thsNqcvAfT09FS5cuXMmsIcGyVPcV4v7dq108aNG3Xo0CFJ0nfffadt27apV69eRXqOsE5GRoaWLVumhx9+WDabTUePHlViYqK6detm1nh4eKhDhw7avn27JGnPnj26fPmyU43D4VB4eLhZk9tx9uzZ47SNJHXr1i3PbVAy3axrJjcpKSmSJH9//yI6G9wMN/uaGTNmjHr37q0uXbpYc0IoNMIWSoSff/5Z8+fPV1hYmD7//HM99thjGjdunN59911JUp06dVStWjVNmzZNycnJysjI0Msvv6zExEQlJCRIklq1aiUfHx9NnTpVFy9e1IULFzR58mRlZWWZNYU5Nkqe4rxepk6dqvvvv1916tSRm5ubmjRposjISN1///035dxx41avXq1z585p+PDhkqTExERJUnBwsFNdcHCwuS4xMVHu7u6qWLFinjVX+/XXX5WZmXnN/aJ0uFnXzNUMw9CECRPUrl07hYeH3+BZ4Ga6mdfMypUrtXfvXkVFRRXhGaCoELZQImRlZalp06aaMWOGmjRpolGjRumRRx7R/PnzJUlubm766KOPdOjQIfn7+8vb21tbtmxRz5495eLiIkmqVKmSPvzwQ61du1bly5eX3W5XSkqKmjZtatYU5tgoeYrzenn//fe1bNkyvffee9q7d6+WLFmiV199VUuWLLkp544bt2jRIvXs2VMOh8Np3GazOS0bhpFj7Gr5qSnMflGy3OxrJtvjjz+u77//XitWrChYwyh2N+uaOXnypMaPH69ly5Y5Pc2BkoOwhRKhcuXKqlevntNY3bp1nT5E3qxZM8XHx+vcuXNKSEhQbGysfvvtN9WoUcOs6datm44cOaKkpCT9+uuvWrp0qU6fPu1UU5hjo2Qpzutl8uTJevLJJ3XfffepQYMGioiI0BNPPMG/KJYSx48f14YNGzRy5EhzLCQkRJJy/MtxUlKS+a/QISEhysjIUHJycp41VwsMDJSLi8s194uS72ZeM381duxYrVmzRps3b1aVKlVu9DRwE93Ma2bPnj1KSkpSs2bN5OrqKldXV23dulVvvPGGXF1d8zWxBqxF2EKJ0LZt2xxT2x46dEjVqlXLUWu321WpUiUdPnxYu3fv1t13352jJjAwUBUqVNCmTZuUlJSkfv36FcmxUTIU5/Vy8eJFlSvn/KvTxcWFqd9LicWLFysoKEi9e/c2x2rUqKGQkBBz5jDpz89bbN26VW3atJH0Z3h3c3NzqklISNC+ffvMmqu5u7urWbNmTttIUlxcXJ7boOS5mdeM9OddjMcff1yrVq3Spk2brvmPPyiZbuY107lzZ/3www+Kj483X82bN9cDDzyg+Pj4az6pgZuk2KbmAP7im2++MVxdXY2XXnrJOHz4sLF8+XLD29vbWLZsmVnzwQcfGJs3bzaOHDlirF692qhWrZoxcOBAp/385z//MXbs2GH89NNPxtKlSw1/f39jwoQJTjV33XWX8eabbxbo2ChZivN6GTZsmHHbbbcZn3zyiXH06FFj1apVRmBgoDFlyhRrTxo3LDMz06hataoxderUHOtefvllw263G6tWrTJ++OEH4/777zcqV65spKammjWPPfaYUaVKFWPDhg3G3r17jbvuusto1KiRceXKFbPm6utl5cqVhpubm7Fo0SLjf//7nxEZGWn4+PgYx44ds/ZkUSSK45r5xz/+YdjtdmPLli1GQkKC+bp48aK1J4siURzXzNWYjbBkIWyhxFi7dq0RHh5ueHh4GHXq1DHefvttp/Wvv/66UaVKFcPNzc2oWrWq8fTTTxvp6elONVOnTjWCg4MNNzc3IywszJg9e7aRlZXlVFOtWjXjueeeK9CxUfIU1/WSmppqjB8/3qhatarh6elp3H777cZTTz2VY98oeT7//HNDknHw4MEc67KysoznnnvOCAkJMTw8PIz27dsbP/zwg1PNpUuXjMcff9zw9/c3vLy8jD59+hgnTpxwqsnt98u//vUvo1q1aoa7u7vRtGlTpvAuRYrjmpGU62vx4sVWnCKKWHH9nvkrwlbJYjMMwyi222oAAAAAcIviM1sAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwCAW8Lw4cPVv3//It9vYmKiunbtKh8fH1WoUOGmHtsK1atX12uvvXbNGpvNptWrV9+UfgDgVkbYAgDkW0kIFceOHZPNZlN8fPxNOd7cuXOVkJCg+Ph4HTp0KNea119/XdHR0Teln7+Kjo7OMwDmZdeuXXr00UetaQgA4MS1uBsAAKAkO3LkiJo1a6awsLA8a+x2+03s6MZUqlSpuFsAgDKDO1sAgCLzv//9T7169VL58uUVHBysiIgI/frrr+b6jh07aty4cZoyZYr8/f0VEhKi6dOnO+3jxx9/VLt27eTp6al69eppw4YNTo+11ahRQ5LUpEkT2Ww2dezY0Wn7V199VZUrV1ZAQIDGjBmjy5cvX7Pn+fPnq2bNmnJ3d1ft2rW1dOlSc1316tX10Ucf6d1335XNZtPw4cNz3cfVd/zyc542m03z589Xz5495eXlpRo1aujDDz8012/ZskU2m03nzp0zx+Lj42Wz2XTs2DFt2bJFDz30kFJSUmSz2WSz2XIcIzdXP0Z4+PBhtW/f3ny/4+LinOozMjL0+OOPq3LlyvL09FT16tUVFRV13eMAAAhbAIAikpCQoA4dOqhx48bavXu3YmNjdfbsWQ0aNMipbsmSJfLx8dHXX3+tWbNm6YUXXjD/gp+VlaX+/fvL29tbX3/9td5++2099dRTTtt/8803kqQNGzYoISFBq1atMtdt3rxZR44c0ebNm7VkyRJFR0df8/G+mJgYjR8/XhMnTtS+ffs0atQoPfTQQ9q8ebOkPx+569GjhwYNGqSEhAS9/vrr+X4/rnWe2Z555hndc889+u677/Tggw/q/vvv14EDB/K1/zZt2ui1116Tn5+fEhISlJCQoEmTJuW7P+nP93vgwIFycXHRzp07tWDBAk2dOtWp5o033tCaNWv0wQcf6ODBg1q2bJmqV69eoOMAQFnFY4QAgCIxf/58NW3aVDNmzDDH/vOf/yg0NFSHDh1SrVq1JEkNGzbUc889J0kKCwvTvHnztHHjRnXt2lXr16/XkSNHtGXLFoWEhEiSXnrpJXXt2tXcZ/ZjcAEBAWZNtooVK2revHlycXFRnTp11Lt3b23cuFGPPPJIrj2/+uqrGj58uEaPHi1JmjBhgnbu3KlXX31VnTp1UqVKleTh4SEvL68cx7qea51ntnvvvVcjR46UJP3zn/9UXFyc3nzzTb311lvX3b+7u7vsdrtsNluBe8u2YcMGHThwQMeOHVOVKlUkSTNmzFDPnj3NmhMnTigsLEzt2rWTzWZTtWrVCnUsACiLuLMFACgSe/bs0ebNm1W+fHnzVadOHUl/fu4pW8OGDZ22q1y5spKSkiRJBw8eVGhoqFN4uPPOO/PdQ/369eXi4pLrvnNz4MABtW3b1mmsbdu2+b67dC3XOs9srVu3zrFcFMfOrwMHDqhq1apm0Mqtp+HDhys+Pl61a9fWuHHjtH79+pvWHwCUdtzZAgAUiaysLPXt21czZ87Msa5y5crmf7u5uTmts9lsysrKkiQZhiGbzVboHq6177xcfbwb7eFGevlrP+XKlTP7yXa9z58V1F/3ffXxszVt2lRHjx7VZ599pg0bNmjQoEHq0qWL/vvf/xZpLwBwK+LOFgCgSDRt2lT79+9X9erVdccddzi9fHx88rWPOnXq6MSJEzp79qw5tmvXLqcad3d3SVJmZuYN91y3bl1t27bNaWz79u2qW7fuDe87P3bu3JljOftuYPbjkgkJCeb6q6e7d3d3v6H3oV69ejpx4oTOnDljju3YsSNHnZ+fnwYPHqx33nlH77//vj766CP9/vvvhT4uAJQV3NkCABRISkpKjr/0+/v7a8yYMXrnnXd0//33a/LkyQoMDNRPP/2klStX6p133nF6vC8vXbt2Vc2aNTVs2DDNmjVL58+fNyfIyL7jEhQUJC8vL8XGxqpKlSry9PQs9NTrkydP1qBBg9S0aVN17txZa9eu1apVq7Rhw4ZC7a+gPvzwQzVv3lzt2rXT8uXL9c0332jRokWSpDvuuEOhoaGaPn26XnzxRR0+fFizZ8922r569epKS0vTxo0b1ahRI3l7e8vb2zvfx+/SpYtq166toUOHavbs2UpNTc0xIcncuXNVuXJlNW7cWOXKldOHH36okJCQAn+/FwCURdzZAgAUyJYtW9SkSROn17PPPiuHw6GvvvpKmZmZ6t69u8LDwzV+/HjZ7XbzkbjrcXFx0erVq5WWlqYWLVpo5MiRevrppyVJnp6ekiRXV1e98cYbWrhwoRwOh+6+++5Cn0v//v31+uuv65VXXlH9+vW1cOFCLV68OMd08lZ5/vnntXLlSjVs2FBLlizR8uXLVa9ePUl/Poa4YsUK/fjjj2rUqJFmzpypF1980Wn7Nm3a6LHHHtPgwYNVqVIlzZo1q0DHL1eunGJiYpSenq4777xTI0eO1EsvveRUU758ec2cOVPNmzdXixYtdOzYMa1bty7fP1MAKMtsRm4PbAMAUEJ89dVXateunX766SfVrFmzuNspMjabTTExMU7fzwUAuLXwGCEAoESJiYlR+fLlFRYWpp9++knjx49X27Ztb6mgBQAoGwhbAIAS5fz585oyZYpOnjypwMBAdenSJcdnlZC7L7/80uk7sq6WlpZ2E7sBAPAYIQAAt4hLly7p9OnTea6/4447bmI3AADCFgAAAABYgKmEAAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALPD/ADVSMJ75A8eoAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'Id', 'tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1268\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
      "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
      "Los resultados deben ser presentados en formato JSON.\n",
      "\n",
      "Categorías de Etiquetado\n",
      "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
      "\n",
      "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
      "\n",
      "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
      "involucrados o mencionados en el texto.\n",
      "\n",
      "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
      "\n",
      "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
      "\n",
      "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
      "\n",
      "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
      "se realizan o suceden las cosas.\n",
      "\n",
      "### Input:\n",
      "Y es que según informa el digital OK Diario, en un artículo que puedes leer en este enlace, el Gobierno de España ha subvencionado con 45.980 euros un estudio sobre el impacto sexista de los piropos.\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset['input'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HOW': ['con 45.980 euros'], 'WHAT': ['un estudio sobre el impacto sexista de los piropos'], 'WHEN': None, 'WHERE': ['en un artículo que puedes leer en este enlace'], 'WHO': ['el digital OK Diario', 'el Gobierno de España'], 'WHY': None}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset['output'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 774, 3133, 3112, 28747, 13, 28738, 28718, 261, 7458, 1037, 2880, 12874, 639, 2245, 28709, 430, 2006, 28717, 296, 1452, 2646, 2562, 921, 283, 337, 4210, 263, 13693, 385, 3753, 9290, 385, 28725, 28705, 13, 28714, 14734, 390, 603, 283, 264, 14150, 13693, 28709, 1849, 911, 2741, 1632, 955, 2977, 28708, 543, 10588, 883, 2166, 340, 543, 5227, 2895, 955, 679, 6863, 28723, 28705, 13, 26102, 1204, 3482, 340, 3173, 1201, 2169, 3482, 481, 1221, 1827, 9292, 28723, 13, 13, 28743, 21800, 12697, 340, 13542, 2741, 299, 1452, 13, 28743, 1540, 13693, 28709, 4210, 28827, 2432, 340, 1105, 23087, 921, 8143, 481, 1849, 340, 2635, 19846, 17459, 20577, 12697, 28747, 13, 13, 20536, 962, 325, 2190, 28797, 1329, 1091, 28877, 4575, 1515, 400, 25786, 28725, 24339, 385, 28725, 289, 13023, 22253, 2442, 28709, 379, 961, 532, 290, 831, 296, 1452, 481, 639, 2245, 28709, 28723, 13, 13, 28780, 4104, 325, 28824, 1724, 2864, 1329, 15220, 20750, 264, 1515, 519, 8358, 385, 289, 936, 11520, 325, 9701, 293, 28725, 6443, 8227, 28725, 4345, 2974, 955, 934, 2892, 28705, 13, 262, 3871, 1485, 28712, 3482, 289, 290, 831, 296, 3482, 481, 639, 2245, 28709, 28723, 13, 13, 20536, 1020, 325, 28743, 28718, 12849, 28709, 1329, 26494, 28706, 1276, 455, 274, 955, 3343, 921, 276, 2470, 385, 289, 3216, 385, 340, 17925, 290, 831, 296, 3482, 481, 639, 2245, 28709, 28723, 13, 13, 28780, 11724, 325, 28757, 28825, 18773, 1329, 9553, 13360, 1515, 9506, 4585, 28725, 7581, 323, 2806, 2970, 21315, 28722, 8368, 289, 3247, 24598, 290, 831, 296, 5959, 481, 639, 2245, 28709, 28723, 13, 13, 20536, 28802, 325, 28753, 271, 25648, 1329, 15220, 20750, 2635, 3599, 293, 28725, 10717, 2402, 289, 8972, 8227, 439, 1256, 5959, 481, 639, 2245, 28709, 28723, 13, 13, 24001, 325, 28743, 28825, 5326, 1329, 27984, 2635, 676, 11234, 28725, 21065, 350, 385, 289, 6803, 321, 19883, 955, 639, 2245, 28709, 1276, 7112, 7469, 21977, 5326, 28705, 13, 331, 16403, 276, 289, 519, 1354, 269, 2635, 6841, 293, 28723, 13, 13, 27332, 11232, 28747, 13, 28802, 1037, 955, 3979, 10167, 5227, 28708, 639, 7153, 12206, 6216, 3756, 28725, 481, 521, 1524, 12639, 28709, 955, 11127, 274, 462, 263, 481, 7021, 481, 22918, 28725, 639, 420, 598, 20122, 340, 20482, 3631, 1083, 28728, 831, 296, 1452, 379, 28705, 28781, 28782, 28723, 28774, 28783, 28734, 317, 22751, 29000, 370, 934, 3704, 7469, 639, 5088, 28709, 3142, 3581, 340, 1515, 284, 4812, 1065, 28723, 13, 13, 27332, 15985, 28747, 13, 18437, 24001, 1869, 5936, 514, 28705, 28781, 28782, 28723, 28774, 28783, 28734, 317, 22751, 5807, 464, 20536, 962, 1869, 5936, 370, 934, 3704, 7469, 639, 5088, 28709, 3142, 3581, 340, 1515, 284, 4812, 1065, 5807, 464, 20536, 1020, 1869, 3635, 28725, 464, 28780, 11724, 1869, 5936, 269, 521, 1524, 12639, 28709, 955, 11127, 274, 462, 263, 481, 7021, 481, 22918, 5807, 464, 28780, 4104, 1869, 5936, 301, 7153, 12206, 6216, 3756, 647, 464, 301, 420, 598, 20122, 340, 20482, 5807, 464, 20536, 28802, 1869, 3635, 28752, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><s> ### Instruction:\n",
      "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
      "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
      "Los resultados deben ser presentados en formato JSON.\n",
      "\n",
      "Categorías de Etiquetado\n",
      "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
      "\n",
      "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
      "\n",
      "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
      "involucrados o mencionados en el texto.\n",
      "\n",
      "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
      "\n",
      "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
      "\n",
      "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
      "\n",
      "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
      "se realizan o suceden las cosas.\n",
      "\n",
      "### Input:\n",
      "Y es que según informa el digital OK Diario, en un artículo que puedes leer en este enlace, el Gobierno de España ha subvencionado con 45.980 euros un estudio sobre el impacto sexista de los piropos.\n",
      "\n",
      "### Output:\n",
      "{'HOW': ['con 45.980 euros'], 'WHAT': ['un estudio sobre el impacto sexista de los piropos'], 'WHEN': None, 'WHERE': ['en un artículo que puedes leer en este enlace'], 'WHO': ['el digital OK Diario', 'el Gobierno de España'], 'WHY': None}</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_train_dataset['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jP3R4enP3m19"
   },
   "source": [
    "### How does the base model do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vxbl4ACsyRgi"
   },
   "source": [
    "Optionally, you can check how Mistral does on one of your data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gOxnx-cAyRgi"
   },
   "outputs": [],
   "source": [
    "eval_prompt = \"\"\"### Instruction:\n",
    "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
    "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
    "Los resultados deben ser presentados en formato JSON.\n",
    "\n",
    "Categorías de Etiquetado\n",
    "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
    "\n",
    "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
    "\n",
    "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
    "involucrados o mencionados en el texto.\n",
    "\n",
    "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
    "\n",
    "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
    "\n",
    "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
    "\n",
    "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
    "se realizan o suceden las cosas.\n",
    "\n",
    "### Input:\n",
    "Y es que según informa el digital OK Diario, en un artículo que puedes leer en este enlace, el Gobierno de España ha subvencionado con 45.980 euros un estudio sobre el impacto sexista de los piropos.\n",
    "\n",
    "### Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "NidIuFXMyRgi",
    "outputId": "b1794b11-9a22-4b0a-e871-7df039ab59fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
      "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
      "Los resultados deben ser presentados en formato JSON.\n",
      "\n",
      "Categorías de Etiquetado\n",
      "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
      "\n",
      "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
      "\n",
      "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
      "involucrados o mencionados en el texto.\n",
      "\n",
      "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
      "\n",
      "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
      "\n",
      "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
      "\n",
      "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
      "se realizan o suceden las cosas.\n",
      "\n",
      "### Input:\n",
      "Y es que según informa el digital OK Diario, en un artículo que puedes leer en este enlace, el Gobierno de España ha subvencionado con 45.980 euros un estudio sobre el impacto sexista de los piropos.\n",
      "\n",
      "### Output:\n",
      "[\n",
      "    {\n",
      "        \"text\": \"Gobierno\",\n",
      "        \"label\": \"WHAT\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"subvenciona\",\n",
      "        \"label\": \"WHAT\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"estudio\",\n",
      "        \"label\": \"WHAT\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"impacto\",\n",
      "        \"label\": \"WHAT\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"sexista\",\n",
      "        \"label\": \"WHAT\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"pirrope\",\n",
      "        \"label\": \"WHAT\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=512, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HOW': ['con 45.980 euros'],\n",
       " 'WHAT': ['un estudio sobre el impacto sexista de los piropos'],\n",
       " 'WHEN': None,\n",
       " 'WHERE': ['en un artículo que puedes leer en este enlace'],\n",
       " 'WHO': ['el digital OK Diario', 'el Gobierno de España'],\n",
       " 'WHY': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'HOW': ['con 45.980 euros'], 'WHAT': ['un estudio sobre el impacto sexista de los piropos'], 'WHEN': None, 'WHERE': ['en un artículo que puedes leer en este enlace'], 'WHO': ['el digital OK Diario', 'el Gobierno de España'], 'WHY': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCAWeCzZyRgi"
   },
   "source": [
    "Observe how the model does out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AapDoyfAyRgi"
   },
   "source": [
    "### 4. Set Up LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp2gMi1ZzGET"
   },
   "source": [
    "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "a9EUEDAl0ss3"
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "gkIcwsSU01EB"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUYEpEK-yRgj"
   },
   "source": [
    "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`, and `lm_head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "XshGNsbxyRgj",
    "outputId": "c619b0e8-8516-4d4b-9abe-13eaa3f3b204",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6mTLuQJyRgj"
   },
   "source": [
    "Here we define the LoRA config.\n",
    "\n",
    "`r` is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
    "\n",
    "`alpha` is the scaling factor for the learned weights. The weight matrix is scaled by `alpha/r`, and thus a higher value for `alpha` assigns more weight to the LoRA activations.\n",
    "\n",
    "The values used in the QLoRA paper were `r=64` and `lora_alpha=16`, and these are said to generalize well, but we will use `r=32` and `lora_alpha=64` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Ybeyl20n3dYH",
    "outputId": "6a16c182-04d9-4812-ae81-502a8fe364d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_FHi_VLyRgn"
   },
   "source": [
    "See how the model looks different now, with the LoRA adapters added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "IaYMWak4yRgn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0MOtwf3zdZp"
   },
   "source": [
    "### 5. Run Training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEe0uWYSyRgo"
   },
   "source": [
    "Overfitting is when the validation loss goes up (bad) while the training loss goes down significantly, meaning the model is learning the training set really well, but is unable to generalize to new datapoints. In most cases, this is not desired.\n",
    "\n",
    "With that said, a note on training: you can set the `max_steps` to be high initially, and examine at what step your model's performance starts to degrade. There is where you'll find a sweet spot for how many steps to perform. For example, say you start with 1000 steps, and find that at around 500 steps the model starts overfitting, as described above. Therefore, 500 steps would be your sweet spot, so you would use the `checkpoint-500` model repo in your output dir.\n",
    "\n",
    "You can interrupt the process via Kernel -> Interrupt Kernel in the top nav bar once you realize you didn't need to train anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "c_L1131GyRgo"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "yxSbpKQSLY6B"
   },
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "jq0nX33BmfaC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1902' max='1902' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1902/1902 50:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.533400</td>\n",
       "      <td>0.283628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.267430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.245100</td>\n",
       "      <td>0.260329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.255700</td>\n",
       "      <td>0.256893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.255634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.249500</td>\n",
       "      <td>0.251843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.255074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.256424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.194500</td>\n",
       "      <td>0.255256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.258334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>0.255899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.176300</td>\n",
       "      <td>0.254251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>0.272127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.276438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.284007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>0.278495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.118600</td>\n",
       "      <td>0.281733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.281570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.281337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1902, training_loss=0.201959881825778, metrics={'train_runtime': 3024.152, 'train_samples_per_second': 1.258, 'train_steps_per_second': 0.629, 'total_flos': 1.149642796990464e+17, 'train_loss': 0.201959881825778, 'epoch': 3.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"flare-finetune-train-split-JSON-Template2\"\n",
    "base_model_name = \"mistral-7b\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_ratio=0.1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=100,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=100,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=100,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9rRmDCeQiTJ"
   },
   "source": [
    "I cleared the output of the cell above because I stopped the training early, and it produced a long, ugly error message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D57XqcsyRgo"
   },
   "source": [
    "### 6. Drum Roll... Try the Trained Model!\n",
    "\n",
    "It's a good idea to kill the current process so that you don't run out of memory loading the base model again on top of the model we just trained. Go to `Kernel > Restart Kernel` or kill the process via the Terminal (`nvidia smi` > `kill [PID]`). \n",
    "\n",
    "By default, the PEFT library will only save the QLoRA adapters, so we need to first load the base model from the Huggingface Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "fb8230fb86884aa6be318e2d03a88af2"
     ]
    },
    "id": "SKSnF016yRgp",
    "outputId": "bce5209d-90da-4117-c6ac-cda9f3cb3422"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec239b994b194886b484fc351deb1d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BxOhAiqyRgp"
   },
   "source": [
    "Now load the QLoRA adapter from the appropriate checkpoint directory, i.e. the best performing model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "model_path = \"mistral-7b-flare-finetune-train-split-JSON-Template2\"\n",
    "ft_model = PeftModel.from_pretrained(base_model, f\"{model_path}/checkpoint-1900\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D57XqcsyRgo"
   },
   "source": [
    "Set stopping criteria to stop the model generating garbage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "class StoppingCriteriaSub(StoppingCriteria):\n",
    "    def __init__(self, stops = [], encounters=1):\n",
    "        super().__init__()\n",
    "        self.stops = [stop.to(\"cuda\") for stop in stops]\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n",
    "        last_token = input_ids[0][-1]\n",
    "        for stop in self.stops:\n",
    "            if tokenizer.decode(stop) == tokenizer.decode(last_token):\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"}\", \"'}}\", \"'}\\n\", \"}}\\n\", \"'}\\n\\n\"]\n",
    "stop_words_ids = [tokenizer(stop_word, return_tensors='pt', add_special_tokens=False)['input_ids'].squeeze() for stop_word in stop_words]\n",
    "stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_words_ids)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lX39ibolyRgp"
   },
   "source": [
    "and run your inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUehsaVNyRgp"
   },
   "source": [
    "Let's try the same `eval_prompt` and thus `model_input` as above, and see if the new finetuned model performs better. I like playing with the repetition penalty (just little tweaks of .01-.05 at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lMkVNEUvyRgp",
    "outputId": "7d49d409-5dbe-4306-c1a4-9d87e3073397"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"### Instruction:\n",
    "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
    "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
    "Los resultados deben ser presentados en formato JSON.\n",
    "\n",
    "Categorías de Etiquetado\n",
    "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
    "\n",
    "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
    "\n",
    "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
    "involucrados o mencionados en el texto.\n",
    "\n",
    "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
    "\n",
    "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
    "\n",
    "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
    "\n",
    "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
    "se realizan o suceden las cosas.\n",
    "\n",
    "### Input:\n",
    "Y es que según informa el digital OK Diario, en un artículo que puedes leer en este enlace, el Gobierno de España ha subvencionado con 45.980 euros un estudio sobre el impacto sexista de los piropos.\n",
    "\n",
    "### Output:\"\"\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    generated_token = ft_model.generate(**model_input, max_new_tokens=512, stopping_criteria=stopping_criteria)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = eval_tokenizer.decode(generated_token, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
      "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
      "Los resultados deben ser presentados en formato JSON.\n",
      "\n",
      "Categorías de Etiquetado\n",
      "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
      "\n",
      "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
      "\n",
      "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
      "involucrados o mencionados en el texto.\n",
      "\n",
      "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
      "\n",
      "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
      "\n",
      "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
      "\n",
      "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
      "se realizan o suceden las cosas.\n",
      "\n",
      "### Input:\n",
      "Y es que según informa el digital OK Diario, en un artículo que puedes leer en este enlace, el Gobierno de España ha subvencionado con 45.980 euros un estudio sobre el impacto sexista de los piropos.\n",
      "\n",
      "### Output:\n",
      "{'HOW': None, 'WHAT': ['un estudio sobre el impacto sexista de los piropos'], 'WHEN': None, 'WHERE': ['en un artículo que puedes leer en este enlace'], 'WHO': ['el digital OK Diario', 'el Gobierno de España'], 'WHY': None}\n"
     ]
    }
   ],
   "source": [
    "print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode only the generated text by slicing the tokens from the length of the input\n",
    "input_length = model_input['input_ids'].size(1)  # Number of tokens in the input\n",
    "generated_text = eval_tokenizer.decode(generated_token[input_length:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'HOW': None, 'WHAT': ['un estudio sobre el impacto sexista de los piropos'], 'WHEN': None, 'WHERE': ['en un artículo que puedes leer en este enlace'], 'WHO': ['el digital OK Diario', 'el Gobierno de España'], 'WHY': None}\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HOW': ['con 45.980 euros'],\n",
       " 'WHAT': ['un estudio sobre el impacto sexista de los piropos'],\n",
       " 'WHEN': None,\n",
       " 'WHERE': ['en un artículo que puedes leer en este enlace'],\n",
       " 'WHO': ['el digital OK Diario', 'el Gobierno de España'],\n",
       " 'WHY': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'HOW': ['con 45.980 euros'], 'WHAT': ['un estudio sobre el impacto sexista de los piropos'], 'WHEN': None, 'WHERE': ['en un artículo que puedes leer en este enlace'], 'WHO': ['el digital OK Diario', 'el Gobierno de España'], 'WHY': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCJnpZoayRgq"
   },
   "source": [
    "### 7. FLARE Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1268, 7)\n",
      "(317, 7)\n"
     ]
    }
   ],
   "source": [
    "# 1 TASK\n",
    "print(tokenized_train_dataset.shape)\n",
    "print(tokenized_val_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
      "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
      "Los resultados deben ser presentados en formato JSON.\n",
      "\n",
      "Categorías de Etiquetado\n",
      "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
      "\n",
      "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
      "\n",
      "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
      "involucrados o mencionados en el texto.\n",
      "\n",
      "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
      "\n",
      "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
      "\n",
      "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
      "\n",
      "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
      "se realizan o suceden las cosas.\n",
      "\n",
      "### Input:\n",
      "\"Es una buena noticia\", ha reivindicado la subdirectora general de Promoción de la Salud, que ha reiterado que desde el departamento catalán consideran que no tendría que haber un límite de edad vinculado a esta vacuna.\n",
      "\n",
      "### Output:\n"
     ]
    }
   ],
   "source": [
    "model_input = f\"{tokenized_val_dataset[0]['input']}\\n\\n### Output:\"\n",
    "print(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    model_input = eval_tokenizer(model_input, return_tensors=\"pt\").to(\"cuda\")\n",
    "    generated_token = ft_model.generate(**model_input, max_new_tokens=512, stopping_criteria=stopping_criteria)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Tu tarea es analizar el texto proporcionado para identificar y extraer fragmentos significativos, \n",
      "luego asignar a cada fragmento una etiqueta que describa la naturaleza de la información que contiene. \n",
      "Los resultados deben ser presentados en formato JSON.\n",
      "\n",
      "Categorías de Etiquetado\n",
      "Cada fragmento extraído debe clasificarse en una de las siguientes categorías:\n",
      "\n",
      "WHAT (Qué): Señala los hechos, objetos, o cualquier elemento concreto mencionado en el texto.\n",
      "\n",
      "WHO (Quién): Identifica a los sujetos o entidades (personas, organizaciones, etc.) que están \n",
      "involucrados o mencionados en el texto.\n",
      "\n",
      "WHEN (Cuándo): Extrae detalles que especifican momentos o periodos de tiempo mencionados en el texto.\n",
      "\n",
      "WHERE (Dónde): Localiza los lugares, espacios geográficos o direcciones mencionadas en el texto.\n",
      "\n",
      "WHY (Por qué): Identifica las causas, razones o motivaciones explicadas en el texto.\n",
      "\n",
      "HOW (Cómo): Describe las maneras, métodos o procedimientos que el texto detalla sobre cómo \n",
      "se realizan o suceden las cosas.\n",
      "\n",
      "### Input:\n",
      "\"Es una buena noticia\", ha reivindicado la subdirectora general de Promoción de la Salud, que ha reiterado que desde el departamento catalán consideran que no tendría que haber un límite de edad vinculado a esta vacuna.\n",
      "\n",
      "### Output:\n",
      "{'HOW': None, 'WHAT': None, 'WHEN': None, 'WHERE': None, 'WHO': ['la subdirectora general de Promoción de la Salud'], 'WHY': None}\n"
     ]
    }
   ],
   "source": [
    "full_text = eval_tokenizer.decode(generated_token, skip_special_tokens=True)\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'HOW': None, 'WHAT': None, 'WHEN': None, 'WHERE': None, 'WHO': ['la subdirectora general de Promoción de la Salud'], 'WHY': None}\n"
     ]
    }
   ],
   "source": [
    "# Decode only the generated text by slicing the tokens from the length of the input\n",
    "input_length = model_input['input_ids'].size(1)  # Number of tokens in the input\n",
    "generated_text = eval_tokenizer.decode(generated_token[input_length:], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'5W1H_Label': 'WHO',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_End': 88,\n",
       "  'Tag_Start': 40,\n",
       "  'Tag_Text': 'la subdirectora general de Promoción de la Salud'},\n",
       " {'5W1H_Label': 'WHERE',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_End': 140,\n",
       "  'Tag_Start': 111,\n",
       "  'Tag_Text': 'desde el departamento catalán'},\n",
       " {'5W1H_Label': 'WHAT',\n",
       "  'Reliability_Label': 'confiable',\n",
       "  'Tag_End': 218,\n",
       "  'Tag_Start': 152,\n",
       "  'Tag_Text': 'que no tendría que haber un límite de edad vinculado a esta vacuna'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_val_dataset[0]['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the generated text transform to FLARE format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ft_model.eval()\n",
    "res = []\n",
    "\n",
    "start_time = time.time()  # Start timing before the loop\n",
    "\n",
    "for x in tokenized_val_dataset:\n",
    "    prompt = f\"{x['input']} Output: \"\n",
    "    model_input = eval_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        generated_token = ft_model.generate(**model_input, max_new_tokens=512, stopping_criteria=stopping_criteria)[0]\n",
    "        input_length = model_input['input_ids'].size(1)  # Number of tokens in the input\n",
    "        generated_text = eval_tokenizer.decode(generated_token[input_length:], skip_special_tokens=True)\n",
    "        res.append(generated_text)\n",
    "        \n",
    "end_time = time.time()  # End timing after the loop\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total time spent generating text: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open(f\"{model_path}/results_1900iter.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(res, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"mistral7b-flare-finetune-train-split-JSON-Template2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load results\n",
    "with open(f\"{model_path}/results_1900iter.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    res = json.load(file)\n",
    "\n",
    "# Load the data\n",
    "task1_train = pd.read_json('../Flares-dataset/5w1h_subtarea_1_train_train.json', lines=True)\n",
    "task1_test = pd.read_json('../Flares-dataset/5w1h_subtarea_1_train_test.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_index_format(data_dict, original_text):\n",
    "    tags_list = []\n",
    "\n",
    "    for label, fragments in data_dict.items():\n",
    "        if fragments is not None:\n",
    "            for fragment in fragments:\n",
    "                start_index = original_text.find(fragment)\n",
    "                if start_index != -1:\n",
    "                    end_index = start_index + len(fragment)\n",
    "                    tags_list.append({\n",
    "                        'Tag_Start': start_index,\n",
    "                        'Tag_End': end_index,\n",
    "                        '5W1H_Label': label,\n",
    "                        'Tag_Text': fragment\n",
    "                    })\n",
    "    \n",
    "    return tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_test['Text'][250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_train['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Initialize an empty list to store the formatted lists\n",
    "all_formatted_lists = []\n",
    "\n",
    "# Assuming 'convert_to_index_format' is a function and 'task1_test' is a dataset with a column 'Text'\n",
    "for i in range(len(task1_test['Text'])):\n",
    "    try:\n",
    "        # Convert the current item and get the formatted list\n",
    "        formatted_list = convert_to_index_format(ast.literal_eval(res[i]), task1_test['Text'][i])\n",
    "\n",
    "        # Append the formatted list to the collection of all formatted lists\n",
    "        all_formatted_lists.append(formatted_list)\n",
    "        \n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        # If an error occurs, simply skip this item and continue with the next\n",
    "        all_formatted_lists.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting each sublist by 'Tag_Start' key\n",
    "sorted_all_formatted_lists = [sorted(sub_list, key=lambda x: x['Tag_Start']) for sub_list in all_formatted_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=1, width=80, depth=None, compact=False)\n",
    "for i in range(0,2):\n",
    "    print(f\"####Generated tags\")\n",
    "    pp.pprint(sorted_all_formatted_lists[i])\n",
    "    print(f\"####Ground Truh tags\")\n",
    "    pp.pprint(tokenized_val_dataset[i]['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract both 'tags' and 'Id' from each entry and store them in a list of dictionaries\n",
    "ground_truth = [{'Id': entry['Id'], 'Tags': f\"{entry['tags']}\"} for entry in tokenized_val_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame using the IDs and the corresponding formatted tag lists\n",
    "tags_df = pd.DataFrame({\n",
    "    'Id': task1_test['Id'],\n",
    "    'Tags': [str(tags) for tags in sorted_all_formatted_lists]  # Convert each list to a string and enclose it in single quotes\n",
    "})\n",
    "\n",
    "print(tags_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save this DataFrame to a CSV file\n",
    "tags_df.to_csv(f\"{model_path}/tags_data_1900iter.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.DataFrame(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save this DataFrame to a CSV file\n",
    "ground_truth.to_csv(f\"{model_path}/ground_truth.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth['Tags'][135]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST FLARE CHALLENGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python \"../evaluate_subtask_1.py\" --pathDataGold /mistral7b-flare-finetune-train-split-JSON-Template2/ground_truth.csv --pathDataInfered /mistral7b-flare-finetune-train-split-JSON-Template2/tags_data_1900iter.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
